<!DOCTYPE html>
<html lang="en"><head>
<script src="chap_5_files/libs/clipboard/clipboard.min.js"></script>
<script src="chap_5_files/libs/quarto-html/tabby.min.js"></script>
<script src="chap_5_files/libs/quarto-html/popper.min.js"></script>
<script src="chap_5_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="chap_5_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="chap_5_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="chap_5_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="chap_5_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="AndrÃ© Victor Ribeiro Amaral">
  <meta name="dcterms.date" content="2025-07-03">
  <title>Statistical Modelling II (MATH3091)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="chap_5_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="chap_5_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="chap_5_files/libs/revealjs/dist/theme/quarto.css">
  <link href="chap_5_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="chap_5_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="chap_5_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="chap_5_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Statistical Modelling II (MATH3091)</h1>
  <p class="subtitle">Part II, Chapter 5: Generalised Linear Models</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<a href="https://www.avramaral.com/">AndrÃ© Victor Ribeiro Amaral</a> 
</div>
<div class="quarto-title-author-email">
<a href="mailto:a.v.ribeiro-amaral@soton.ac.uk">a.v.ribeiro-amaral@soton.ac.uk</a>
</div>
        <p class="quarto-title-affiliation">
            University of Southampton
          </p>
    </div>
</div>

  <p class="date">07/03/2025</p>
</section>
<section id="preface" class="slide level2">
<h2>Preface</h2>
<div class="center-vertically-only">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>&nbsp;</strong></p>
</div>
<div class="callout-content">
<p>The aim of this chapter is to cover the theory and application of generalised linear models (GLMs).</p>
<p>These slides are based on material written by previous lecturers of this course, including <em>Sujit Sahu</em>, <em>Dave Woods</em>, and <em>Chao Zheng</em>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="schedule" class="slide level2">
<h2>Schedule</h2>
<div class="small-text center-vertically">
<table class="caption-top">
<colgroup>
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 22%">
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Week</th>
<th>Lab</th>
<th>Session 1 (Thursday)</th>
<th>Session 2 (Friday)</th>
<th>Session 3 (Friday)</th>
<th>Problem sheet</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>07</td>
<td>No lab</td>
<td>5.1 Exponential family</td>
<td>5.2 Components of a GLM</td>
<td>5.3 Examples of GLMs</td>
<td>Sheet 4</td>
</tr>
<tr class="even">
<td>08</td>
<td>Lab 5</td>
<td>5.4 MLE</td>
<td>5.5 Confidence intervals</td>
<td>PC: sheet 4</td>
<td></td>
</tr>
<tr class="odd">
<td>09</td>
<td>Lab 6</td>
<td>5.6 Comparing GLMs</td>
<td>5.7 Deviance</td>
<td>5.8 Models with unknown scale</td>
<td>Sheet 5</td>
</tr>
<tr class="even">
<td>10</td>
<td>Lab 7</td>
<td>6.1 Contingency tables</td>
<td>6.2 Log-linear models</td>
<td>PC: sheet 5</td>
<td></td>
</tr>
<tr class="odd">
<td>11</td>
<td>Lab 8</td>
<td>6.3 Multinomial sampling</td>
<td>6.4 Interpretation for two-way tables</td>
<td>6.5 Interpretation for multiway tables</td>
<td>Sheet 6</td>
</tr>
<tr class="even">
<td>12</td>
<td>Lab 9</td>
<td>Revision</td>
<td>Revision</td>
<td>PC: sheet 6</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.1-exponential-family" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.1: Exponential family</h1>

</section>
<section id="linear-model-quiz-01-vevox.app-160-892-474" class="slide level2">
<h2>Linear model quiz 01 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>

<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-1-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"><p>Does it look like a linear model might be appropriate here?</p>
</section>
<section id="linear-model-quiz-02-vevox.app-160-892-474" class="slide level2">
<h2>Linear model quiz 02 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>

<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-2-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"><p>Does it look like a linear model might be appropriate here?</p>
</section>
<section id="linear-model-quiz-03-vevox.app-160-892-474" class="slide level2">
<h2>Linear model quiz 03 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>

<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-3-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"><p>Does it look like a linear model might be appropriate here?</p>
</section>
<section id="linear-model-quiz-04-vevox.app-160-892-474" class="slide level2">
<h2>Linear model quiz 04 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>

<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-4-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"><p>Does it look like a linear model might be appropriate here?</p>
</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<p>The linear model in Chapter 3 assumes each response <span class="math inline">\(Y_i \sim N(\mu_i, \sigma^2)\)</span>, where the mean <span class="math inline">\(\mu_i\)</span> depends on explanatory variables through <span class="math inline">\(\mu_i = x_i^{\top} \beta\)</span>.</p>
<div class="fragment">
<p>For many types of data, this assumption of normality of the response may not be justified. For instance, we might have</p>
<ul>
<li>Binary response <span class="math inline">\((Y_i \in \{0, 1\})\)</span>, e.g., representing whether or not a patient recovers from a disease. A natural model is that <span class="math inline">\(Y_i \sim \text{Bernoulli}(p_i)\)</span>, and we might want to model how the âsuccessâ probability <span class="math inline">\(p_i\)</span> depends on explanatory variables <span class="math inline">\(x_i\)</span>.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Count response <span class="math inline">\((Y_i \in \{0, 1, 2, 3, \cdots\})\)</span>, e.g., representing the number of customers arriving at a shop. A natural model is that <span class="math inline">\(Y_i \sim \text{Poisson}(\lambda_i)\)</span>, and we might want to model how the rate <span class="math inline">\(\lambda_i\)</span> depends on explanatory variables.</li>
</ul>
</div>
</section>
<section id="introduction-1" class="slide level2">
<h2>Introduction</h2>
<p>Next, we define the <strong>exponential family</strong>, which includes the Bernoulli and Poisson distributions as special cases. <span class="alert">In a generalised linear model, the response distribution is assumed to be a member of the exponential family</span>.</p>
<div class="fragment">
<p>To complete the specification of a generalised linear model, we will need to model how the parameters of the response distribution (e.g.&nbsp;the success probability <span class="math inline">\(p_i\)</span> or the rate <span class="math inline">\(\lambda_i\)</span>) depend on explanatory variables <span class="math inline">\(x_i\)</span>. We need to do this in a way which respects constraints on the possible values which these parameters may take; for instance, we <strong>should not</strong> model <span class="math inline">\(p_i = x_i^{\top} \beta\)</span> directly, as we need to enforce <span class="math inline">\(p_i \in [0, 1]\)</span>.</p>
</div>
</section>
<section id="exponential-family" class="slide level2">
<h2>Exponential family</h2>
<div class="large-text">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>A probability distribution is said to be a member of the exponential family if its probability density function (or probability function, if discrete) can be written in the form</p>
<p><span id="eq-exp-fam"><span class="math display">\[
f_Y(y;\theta,\phi)=\exp\left({{y\theta-b(\theta)}\over{a(\phi)}} +c(y,\phi)\right),
\qquad(1)\]</span></span></p>
<p>where the parameter <span class="math inline">\(\theta\)</span> is called the <em>natural</em> or <em>canonical</em> parameter. The parameter <span class="math inline">\(\phi\)</span> is usually assumed known. If it is unknown then it is often called the <em>nuisance</em> parameter.</p>
</div>
</div>
</div>
</div>
</section>
<section id="exponential-family-1" class="slide level2">
<h2>Exponential family</h2>
<p>Let <span class="math inline">\(Y\)</span> be a random variable with density <span class="math inline">\(f_Y(y;\theta,\phi)\)</span> as in <a href="#/exponential-family" class="quarto-xref">Equation&nbsp;1</a>, then</p>
<p><span class="math display">\[
\mathbb{E}(Y) = b'(\theta)~~~~~\text{and}~~~~~ \text{Var}(Y) = a(\phi)b''(\theta).
\]</span></p>
<div class="fragment">
<p>We often denote the mean by <span class="math inline">\(\mu\)</span>, so <span class="math inline">\(\mu = b'(\theta)\)</span>.</p>
</div>
<div class="fragment">
<p>The variance is a product of two functions</p>
<ol type="1">
<li><span class="math inline">\(b''(\theta)\)</span> depends on the canonical parameter <span class="math inline">\(\theta\)</span> (and hence <span class="math inline">\(\mu\)</span>) only and is called the <em>variance function</em> (<span class="math inline">\(V(\mu)\equiv b''(\theta)\)</span>).</li>
<li><span class="math inline">\(a(\phi)\)</span> is sometimes of the form <span class="math inline">\(a(\phi)=\sigma^2/w\)</span> where <span class="math inline">\(w\)</span> is a known <em>weight</em> and <span class="math inline">\(\sigma^2\)</span> is called the <em>dispersion parameter</em> or <em>scale parameter</em>.</li>
</ol>
</div>
</section>
<section id="exponential-family-proof" class="slide level2">
<h2>Exponential family (proof)</h2>
<div class="small-text">
<p><a href="#/exponential-family" class="quarto-xref">Equation&nbsp;1</a> can be thought of as a likelihood resulting from a single observation <span class="math inline">\(y\)</span>. Therefore,</p>
<p><span class="math display">\[\ell(\theta,\phi)={{y\theta-b(\theta)}\over{a(\phi)}} +c(y,\phi)\]</span></p>
<div class="fragment">
<p>and the score is</p>
<p><span class="math display">\[u(\theta)=\frac{\partial}{\partial \theta}\ell(\theta,\phi) ={{y-\frac{\partial}{\partial \theta} b(\theta)}\over{a(\phi)}} ={{y- b'(\theta)}\over{a(\phi)}}.\]</span></p>
</div>
<div class="fragment">
<p>The Hessian is</p>
<p><span class="math display">\[H(\theta)=\frac{\partial^2}{\partial \theta^2}\ell(\theta,\phi) =-{{\frac{\partial^2}{\partial \theta^2} b(\theta)}\over{a(\phi)}} =-{{b''(\theta)}\over{a(\phi)}}\]</span></p>
</div>
<div class="fragment">
<p>so the expected information is</p>
<p><span class="math display">\[{\cal I}(\theta)=\mathbb{E}[-H(\theta)]=b''(\theta)/a(\phi).\]</span></p>
</div>
</div>
</section>
<section id="exponential-family-proof-continued" class="slide level2">
<h2>Exponential family (proof continued)</h2>
<div class="small-text">
<p>From the properties of the score function (Chapter 2), we know that <span class="math inline">\(\mathbb{E}[U(\theta)]=0\)</span>. Therefore,</p>
<p><span class="math display">\[\mathbb{E}\left[{{Y- b'(\theta)}\over{a(\phi)}}\right]=0,\]</span></p>
<p>so <span class="math inline">\(\mathbb{E}[Y]=b'(\theta)\)</span>. We often denote the mean by <span class="math inline">\(\mu\)</span>, so <span class="math inline">\(\mu=b'(\theta)\)</span>.</p>
<div class="fragment">
<p>Furthermore, <span class="math display">\[
\text{Var}[U(\theta)]=
\text{Var}\left[{{Y- b'(\theta)}\over{a(\phi)}}\right]=
{{\text{Var}[Y]}\over{a(\phi)^2}},
\]</span></p>
<p>as <span class="math inline">\(b'(\theta)\)</span> and <span class="math inline">\(a(\phi)\)</span> are constants (not random variables).</p>
</div>
<div class="fragment">
<p>We also know that <span class="math inline">\(\text{Var}[U(\theta)]={\cal I}(\theta)\)</span> (Chapter 2). Therefore,</p>
<p><span class="math display">\[
\text{Var}[Y]=a(\phi)^2\text{Var}[U(\theta)]=a(\phi)^2 {\cal I}(\theta)
= a(\phi)b''(\theta).
\]</span></p>
</div>
</div>
</section>
<section id="example-bernoulli-distribution" class="slide level2">
<h2>Example (Bernoulli distribution)</h2>
<div class="small-text">
<p>Suppose <span class="math inline">\(Y \sim \text{Bernoulli}(p)\)</span>. Then,</p>
<p><span class="math display">\[\begin{align*}
f_Y(y;p)&amp;= p^y(1-p)^{1-y}\qquad y\in\{0,1\};\quad
p\in(0,1)\cr
&amp;= \exp\left(y\log{p\over{1-p}}+\log(1-p)\right)
\end{align*}\]</span></p>
<div class="fragment">
<p>This is in the form of <a href="#/exponential-family" class="quarto-xref">Equation&nbsp;1</a>, with <span class="math inline">\(\theta=\log{p\over{1-p}}\)</span>, <span class="math inline">\(b(\theta)=\log(1+\exp\theta)\)</span>, <span class="math inline">\(a(\phi)=1\)</span> and <span class="math inline">\(c(y,\phi)=0\)</span>.</p>
</div>
<div class="fragment">
<p>Therefore, <span class="math display">\[\mathbb{E}(Y)=b'(\theta)={{\exp\theta}\over{1+\exp\theta}}=p~~~~~\text{and}~~~~~\text{Var}(Y)=a(\phi)b''(\theta)={{\exp\theta}\over{(1+\exp\theta})^2}=p(1-p)\]</span> and the variance function is <span class="math display">\[V(\mu)=\mu(1-\mu).\]</span></p>
</div>
</div>
</section>
<section id="example-poisson-distribution" class="slide level2">
<h2>Example (Poisson distribution)</h2>
<div class="small-text">
<p>Suppose <span class="math inline">\(Y \sim \text{Poisson}(\lambda)\)</span>. Then,</p>
<p><span class="math display">\[\begin{align*}
f_Y(y;\lambda)&amp;= {{\exp(-\lambda)\lambda^y}\over{y!}}
\qquad y\in\{0,1,\cdots\};\quad\lambda\in{\mathbb R}_+\cr
&amp;= \exp\left(y\log\lambda-\lambda-\log y!\right).
\end{align*}\]</span></p>
<div class="fragment">
<p>This is in the form <a href="#/exponential-family" class="quarto-xref">Equation&nbsp;1</a>, with <span class="math inline">\(\theta=\log\lambda\)</span>, <span class="math inline">\(b(\theta)=\exp\theta\)</span>, <span class="math inline">\(a(\phi)=1\)</span> and <span class="math inline">\(c(y,\phi)=-\log y!\)</span>.</p>
</div>
<div class="fragment">
<p>Therefore, <span class="math display">\[\mathbb{E}(Y)=b'(\theta)=\exp\theta=\lambda~~~~~\text{and}~~~~~\text{Var}(Y)=a(\phi)b''(\theta)=\exp\theta=\lambda \]</span> and the variance function is <span class="math display">\[V(\mu)=\mu.\]</span></p>
</div>
</div>
</section>
<section id="example-normal-distribution" class="slide level2">
<h2>Example (Normal distribution)</h2>
<div class="small-text">
<p>Suppose <span class="math inline">\(Y\sim \text{Normal}(\mu, \, \sigma^2)\)</span>. Then,</p>
<p><span class="math display">\[\begin{align*}
f_Y(y;\mu,\sigma^2)= {1\over{\sqrt{2\pi\sigma^2}}}
\exp\left(-{1\over{2\sigma^2}}(y-\mu)^2\right)\quad\;\; y\in\mathbb{R};\;\;\mu\in\mathbb{R}\cr
= \exp\left({{y\mu-{1\over 2}\mu^2}\over \sigma^2}-{1\over 2}\left[
{{y^2}\over\sigma^2}+\log(2\pi\sigma^2)\right]\right).
\end{align*}\]</span></p>
<div class="fragment">
<p>This is in the form of <a href="#/exponential-family" class="quarto-xref">Equation&nbsp;1</a>, with <span class="math inline">\(\theta=\mu\)</span>, <span class="math inline">\(b(\theta)={1\over 2}\theta^2\)</span>, <span class="math inline">\(a(\phi)=\sigma^2\)</span> and</p>
<p><span class="math display">\[
c(y,\phi)=-{1\over 2}\left[
{{y^2}\over{a(\phi)}}+\log(2\pi\sigma^2)\right].
\]</span></p>
</div>
<div class="fragment">
<p>Therefore, <span class="math display">\[\mathbb{E}(Y)=b'(\theta)=\theta=\mu~~~~~\text{and}~~~~~\text{Var}(Y)=a(\phi)b''(\theta)=\sigma^2\]</span> and the variance function is <span class="math display">\[V(\mu)=1.\]</span></p>
</div>
</div>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have defined the Exponential family, showed that it contains many common distributions, and found simple expressions for the mean and variance.</li>
<li>In a generalised linear model, the distribution of the response is assumed to be a member of the exponential family.</li>
<li>To complete the model, we still need to write down how the mean <span class="math inline">\(\mu_i\)</span> depends on explanatory variables. We will look at this next time.</li>
</ul>
<!---
:::{.callout-note .fragment}
You should now be able to complete questions 1 and 2 on problem sheet 3.
:::
-->
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.2-componentes-of-a-glm" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.2: Componentes of a GLM</h1>

</section>
<section id="recap" class="slide level2">
<h2>Recap</h2>
<p>A probability distribution is said to be a member of the <span class="alert">exponential family</span> if its probability density function (or probability function, if discrete) can be written in the form</p>
<p><span class="math display">\[
f_Y(y;\theta,\phi)=\exp\left({{y\theta-b(\theta)}\over{a(\phi)}} +c(y,\phi)\right),
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\mathbb{E}(Y) = b'(\theta)~~~~~\text{and}~~~~~ \text{Var}(Y) = a(\phi)b''(\theta).
\]</span></p>
</section>
<section id="components-of-a-generalised-linear-model-glm" class="slide level2">
<h2>Components of a Generalised Linear Model (GLM)</h2>
<p>As in a linear model, the aim is to determine the pattern of dependence of a response variable on explanatory variables.</p>
<p>We denote the <span class="math inline">\(n\)</span> observations of the response by <span class="math inline">\(\mathbf{y}=(y_1,y_2,\cdots ,y_n)^{\top}\)</span>, assumed to be observations of the random variables <span class="math inline">\(\mathbf{Y}=(Y_1,Y_2,\cdots ,Y_n)^{\top}\)</span>.</p>
<p>Associated with each <span class="math inline">\(y_i\)</span> is a vector <span class="math inline">\(\mathbf{x}_i=(x_{i1},x_{i2},\cdots ,x_{ip})^{\top}\)</span> of <span class="math inline">\(p\)</span> explanatory variables.</p>
<p>In this setting, we want to model how the distribution of <span class="math inline">\(Y_i\)</span> depends on <span class="math inline">\(\mathbf{x}_i\)</span>.</p>
</section>
<section id="the-random-component" class="slide level2">
<h2>The random component</h2>
<p>In a GLM, each <span class="math inline">\(Y_i\)</span> is assumed to be an independent random variable. All the <span class="math inline">\(Y_i\)</span>âs are assumed to have distribution coming from the same exponential family, but with a potentially different value of the parameters.</p>
<p>The functions <span class="math inline">\(a(\cdot)\)</span>, <span class="math inline">\(b(\cdot)\)</span> and <span class="math inline">\(c(\cdot)\)</span> are the same for each <span class="math inline">\(Y_i\)</span>, but the canonical parameter <span class="math inline">\(\theta\)</span> (and sometimes the scale parameter <span class="math inline">\(\phi\)</span>) may differ.</p>
<p>We have <span class="math display">\[
f_{Y_i}(y_i;\theta_i,\phi_i)=
\exp\left({{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}}
+c(y_i,\phi_i)\right)
\]</span> for <span class="math inline">\(i = 1, \cdots, n\)</span>, where <span class="math inline">\(\boldsymbol{\theta}=(\theta_1,\cdots ,\theta_n)^{\top}\)</span> is the collection of canonical parameters and <span class="math inline">\(\boldsymbol{\phi}=(\phi_1,\cdots ,\phi_n)^T\)</span> is the collection of nuisance parameters (where they exist).</p>
</section>
<section id="likelihood-for-boldsymboltheta-and-boldsymbolphi" class="slide level2">
<h2>Likelihood for <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\phi}\)</span></h2>
<p>For a particular sample of observed responses, <span class="math inline">\(\mathbf{y}=(y_1,y_2,\cdots ,y_n)^{\top}\)</span>, the likelihood function for <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\phi}\)</span> is <span class="math display">\[\begin{align*}
\mathcal{L}(\boldsymbol{\theta}, \boldsymbol{\phi}) &amp;= \prod_{i=1}^n f_{Y_i}(y_i;\theta_i,\phi_i) \\
&amp;= \exp\left(\sum_{i=1}^n{{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}}
+\sum_{i=1}^nc(y_i,\phi_i)\right)
\end{align*}\]</span></p>
<div class="fragment">
<p>However, we <strong>do not</strong> want to estimate <span class="math inline">\(\boldsymbol\theta\)</span> and <span class="math inline">\(\boldsymbol\phi\)</span> directly.</p>
</div>
</section>
<section id="bernoulli-example" class="slide level2">
<h2>Bernoulli example</h2>
<p>Suppose I ask the entire MATH3091 class a question, e.g.,</p>
<div class="small-text centering">
<p><span class="alert">âWhat is the MLE of the Poisson rate parameter <span class="math inline">\(\lambda\)</span>, given samples <span class="math inline">\(y_1, \cdots, y_n\)</span>?â</span></p>
</div>
<p>Let <span class="math display">\[
Y_i = \begin{cases} 1 &amp; \text{if person $i$ gets question correct} \\
0 &amp; \text{otherwise}. \end{cases}
\]</span></p>
<p>We can model <span class="math inline">\(Y_i \sim \text{Bernoulli}(p_i)\)</span>, where <span class="math inline">\(p_i\)</span> is the unknown probability that person <span class="math inline">\(i\)</span> will get the question correct.</p>
<p>The response distribution belongs to the exponential family, with canonical parameter <span class="math inline">\(\theta_i = \log\left(\frac{p_i}{1 - p_i}\right)\)</span>, and with no scale parameter, i.e., <span class="math inline">\(a(\phi) = 1\)</span>.</p>
</section>
<section id="mle-for-p_1-vevox.app-160-892-474" class="slide level2">
<h2>MLE for <span class="math inline">\(p_1\)</span> (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<p>Suppose <span class="math inline">\(n = 10\)</span>, and <span class="math inline">\(\mathbf{y} = (1, 0, 0, 1, 1, 1, 1, 0, 0, 1)^{\top}\)</span>.</p>
<p>What is the MLE of <span class="math inline">\(p_1\)</span>?</p>
<ul>
<li><span class="math inline">\(\hat p_1 = 0\)</span></li>
<li><span class="math inline">\(\hat p_1 = 1 - \bar y = 0.4\)</span></li>
<li><span class="math inline">\(\hat p_1 = \bar y = 0.6\)</span></li>
<li><span class="math inline">\(\hat p_1 = 1\)</span></li>
</ul>
</section>
<section id="mle-for-p_2-vevox.app-160-892-474" class="slide level2">
<h2>MLE for <span class="math inline">\(p_2\)</span> (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<p>Suppose <span class="math inline">\(n = 10\)</span>, and <span class="math inline">\(\mathbf{y} = (1, 0, 0, 1, 1, 1, 1, 0, 0, 1)^{\top}\)</span>.</p>
<p>What is the MLE of <span class="math inline">\(p_2\)</span>?</p>
<ul>
<li><span class="math inline">\(\hat p_2 = 0\)</span></li>
<li><span class="math inline">\(\hat p_2 = 1 - \bar y = 0.4\)</span></li>
<li><span class="math inline">\(\hat p_2 = \bar y = 0.6\)</span></li>
<li><span class="math inline">\(\hat p_2 = 1\)</span></li>
</ul>
<div class="fragment">
<p>We are not really interested in the individual <span class="math inline">\(p_i\)</span>. <span class="alert">Instead, we might be interested in modelling each <span class="math inline">\(p_i\)</span> as a function of explanatory variables <span class="math inline">\({\mathbf x}_i\)</span></span> (e.g.&nbsp;number of lectures person <span class="math inline">\(i\)</span> attended, whether person <span class="math inline">\(i\)</span> completed problem sheet 1, etc.).</p>
</div>
</section>
<section id="the-systematic-or-structural-component" class="slide level2">
<h2>The systematic (or structural) component</h2>
<p>In a GLM, the distribution of the response variable <span class="math inline">\(Y_i\)</span> depends on <span class="math inline">\(\mathbf{x}_i\)</span> through the <span class="alert">linear predictor</span> <span class="math inline">\(\eta_i\)</span>, such that <span class="math display">\[\begin{align*}
\eta_i &amp;=\beta_1 x_{i1} +\beta_2 x_{i2} + \cdots + \beta_p x_{ip} = \sum_{j=1}^p x_{ij} \beta_j =  \mathbf{x}_i^T \boldsymbol{\beta} = [\mathbf{X}\boldsymbol{\beta}]_i,
\end{align*}\]</span> where, <span class="math inline">\(i = 1,\cdots, n\)</span>, as with a linear model, <span class="math display">\[
\mathbf{X}=\begin{pmatrix} \mathbf{x}_1^{\top}\cr\vdots\cr \mathbf{x}_n^{\top} \end{pmatrix}
=\begin{pmatrix}
x_{11}&amp;\cdots&amp;x_{1p}\cr\vdots&amp;\ddots&amp;\vdots\cr x_{n1}&amp;\cdots&amp;x_{np}\end{pmatrix}
\]</span> and <span class="math inline">\(\boldsymbol{\beta}=(\beta_1,\cdots ,\beta_p)^{\top}\)</span> is a vector of unknown parameters.</p>
</section>
<section id="the-design-matrix" class="slide level2">
<h2>The design matrix</h2>
<p>There are different ways to describe the linear predictor, however, the most economical is the matrix form <span class="math display">\[\boldsymbol{\eta}=\mathbf{X}\boldsymbol{\beta}.\]</span></p>
<p>Again, we call the <span class="math inline">\(n\times p\)</span> matrix <span class="math inline">\(\mathbf{X}\)</span> the <em>design matrix</em>.</p>
<p>The <span class="math inline">\(i\)</span>-th row of <span class="math inline">\(\mathbf{X}\)</span> is <span class="math inline">\(\mathbf{x}_i^{\top}\)</span>, the explanatory data corresponding to the <span class="math inline">\(i\)</span>-th observation of the response. The <span class="math inline">\(j\)</span>-th column of <span class="math inline">\(\mathbf{X}\)</span> contains the <span class="math inline">\(n\)</span> observations of the <span class="math inline">\(j\)</span>-th explanatory variable.</p>
</section>
<section id="the-link-function" class="slide level2">
<h2>The link function</h2>
<p>For specifying the pattern of dependence of the response variable on the explanatory variables, the canonical parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> are not of direct interest.</p>
<p>Recall that the distribution of <span class="math inline">\(Y_i\)</span> should depend on <span class="math inline">\(\mathbf{x}_i\)</span> through <span class="math inline">\(\eta_i\)</span>. It is the parameters <span class="math inline">\(\beta_1, \cdots ,\beta_p\)</span> of the linear predictor which are of primary interest.</p>
<p>The link between the distribution of <span class="math inline">\(\mathbf{Y}\)</span> and <span class="math inline">\(\mathbf{\eta}\)</span> is given by the <span class="alert">link function</span> <span class="math inline">\(g\)</span>, <span class="math display">\[
\eta_i=g(\mu_i),\quad i = 1, \cdots, n,
\]</span> where <span class="math inline">\(\mu_i\equiv \mathbb{E}(Y_i),\;i = 1, \cdots, n\)</span>.</p>
<p>So the dependence of the distribution of <span class="math inline">\(Y_i\)</span> on explanatory variables is <span class="math display">\[
g(\mathbb{E}[Y_i])=g(\mu_i)=\eta_i=\mathbf{x}_i^{\top}\boldsymbol{\beta},\quad i = 1, \cdots, n.
\]</span></p>
</section>
<section id="bernoulli-example-1" class="slide level2">
<h2>Bernoulli example</h2>
<div class="small-text">
<p>Returning to our previous example, where</p>
<p><span class="math display">\[
Y_i = \begin{cases} 1 &amp; \text{if person $i$ gets question correct,} \\
0 &amp; \text{otherwise}, \end{cases}
\]</span> and <span class="math inline">\(Y_i \sim \text{Bernoulli}(p_i)\)</span>, we have <span class="math inline">\(\mu_i = \mathbb{E}(Y_i) = p_i\)</span>.</p>
<div class="fragment">
<p><span class="math display">\[
\text{Let}~~~x_i = \begin{cases} 1 &amp; \text{if person $i$ has completed problem sheet 1,} \\
0 &amp; \text{otherwise}, \end{cases}
\]</span> and <span class="math display">\[\eta_i = \beta_1 + \beta_2 x_i.\]</span></p>
</div>
<div class="fragment">
<p>We would like to choose a link function <span class="math inline">\(g(p_i) = \eta_i\)</span> with the following properties</p>
<ul>
<li><span class="math inline">\(\eta_i \in \mathbb{R}\)</span>, <span class="math inline">\(p_i \in (0, 1)\)</span>, so <span class="math inline">\(g: (0, 1) \to \mathbb{R}\)</span></li>
<li>As <span class="math inline">\(\eta_i \to \infty\)</span>, <span class="math inline">\(p_i = g^{-1}(\eta_i) \to 1\)</span>.</li>
<li>As <span class="math inline">\(\eta_i \to -\infty\)</span>, <span class="math inline">\(p_i = g^{-1}(\eta_i) \to 0\)</span>.</li>
</ul>
</div>
</div>
</section>
<section id="choosing-the-link-function" class="slide level2">
<h2>Choosing the link function</h2>
<p>In principle, the link function <span class="math inline">\(g\)</span> can be any one-to-one differentiable function.</p>
<p>However, <span class="math inline">\(\eta_i\)</span> can take any value in <span class="math inline">\(\mathbb{R}\)</span> (as we make no restriction on possible values taken by explanatory variables or model parameters).</p>
<p>Recall that for some exponential family distributions <span class="math inline">\(\mu_i\)</span> is restricted. For example, for the <span class="alert">Poisson distribution</span> <span class="math inline">\(\mu_i\in\mathbb{R}_+\)</span>; for the <span class="alert">Bernoulli distribution</span> <span class="math inline">\(\mu_i\in(0,1)\)</span>.</p>
<p>If <span class="math inline">\(g\)</span> is not chosen carefully, then there may exist a possible <span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> such that <span class="math inline">\(\eta_i\ne g(\mu_i)\)</span> for any possible value of <span class="math inline">\(\mu_i\)</span>.</p>
<p>Therefore, <strong><em>sensible</em></strong> choices of link function map the set of allowed values for <span class="math inline">\(\mu_i\)</span> onto <span class="math inline">\(\mathbb{R}\)</span>.</p>
</section>
<section id="likelihood-for-boldsymbolbeta" class="slide level2">
<h2>Likelihood for <span class="math inline">\(\boldsymbol\beta\)</span></h2>
<p>The likelihood function for <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\phi}\)</span> is <span class="math display">\[
\mathcal{L}(\boldsymbol{\theta}, \boldsymbol{\phi}) = \exp\left(\sum_{i=1}^n{{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}}
+\sum_{i=1}^nc(y_i,\phi_i)\right).
\]</span> So the likelihood function for <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{\phi}\)</span> is (<span class="math inline">\(\mu_i = \mathbb{E}(Y_i) = b'(\theta_i)\)</span>) <span class="math display">\[
\mathcal{L}(\boldsymbol{\beta}, \boldsymbol{\phi}) = \exp\left(\sum_{i=1}^n{{y_i b^{'-1}(g^{-1}(\mathbf{x}_i^{\top}\boldsymbol{\beta})-b(b^{'-1}(g^{-1}(\mathbf{x}_i^{\top}\boldsymbol{\beta}))}\over{a(\phi_i)}} +\sum_{i=1}^nc(y_i,\phi_i)\right).
\]</span> We will assume for now that <span class="math inline">\(\mathbf \phi\)</span> is known. Later, we will also with cases where <span class="math inline">\(\phi_i = \sigma^2/m_i\)</span>, where <span class="math inline">\(\sigma^2\)</span> is an unknown dispersion parameter, and <span class="math inline">\(m_i\)</span> are known weights.</p>
</section>
<section id="canonical-link" class="slide level2">
<h2>Canonical link</h2>
<div class="small-text">
<p>We have <span class="math display">\[
\theta_i=b^{'-1}(g^{-1}(\mathbf{x}_i^{\top}\boldsymbol{\beta})),\quad i = 1, \cdots, n.
\]</span></p>
<p>If <span class="math inline">\(g\)</span> and <span class="math inline">\(b^{'-1}\)</span> are identical, then <span class="math display">\[
\theta_i=\mathbf{x}_i^{\top}\boldsymbol{\beta}\qquad i = 1, \cdots, n
\]</span> and the resulting likelihood is <span class="math display">\[
\mathcal{L}(\boldsymbol{\beta})=
\exp\left(\sum_{i=1}^n{{y_i\mathbf{x}_i^{\top}\boldsymbol{\beta}-b(\mathbf{x}_i^{\top}\boldsymbol{\beta})}\over{a(\phi_i)}}
+\sum_{i=1}^nc(y_i,\phi_i)\right).
\]</span> The link function <span class="math display">\[
g(\mu)\equiv b^{'-1}(\mu)
\]</span> is called the <strong><em>canonical link function</em></strong>. Under the canonical link, the canonical parameter is equal to the linear predictor.</p>
</div>
</section>
<section id="bernoulli-example-2" class="slide level2">
<h2>Bernoulli example</h2>
<p>Returning to our previous example, we can compute the canonical link function for <span class="math inline">\(Y \sim \text{Bernoulli}(p)\)</span>, where <span class="math inline">\(\mu = \mathbb{E}(Y) = p\)</span>.</p>
<p>Recall that, for the Bernoulli distribution (previous lecture), <span class="math display">\[
b(p) = \log(1 + \exp p)
\]</span> Thus, the canonical link is <span class="math display">\[\begin{align*}
\frac{d}{dp}b(p) = b'(p) &amp;= \frac{\exp p}{1 + \exp p} \\
                   \mu   &amp;=  \frac{\exp p}{1 + \exp p} \implies p = \log\left(\frac{\mu}{1 - \mu}\right) = \text{logit}(\mu),
\end{align*}\]</span> i.e., the canonical link function for this example is <span class="math inline">\(g(\mu) = \text{logit}(\mu)\)</span>.</p>
</section>
<section id="canonical-link-functions" class="slide level2">
<h2>Canonical link functions</h2>
<div class="center-vertically">
<table class="caption-top">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 15%">
<col style="width: 16%">
<col style="width: 21%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th><span class="math inline">\(b(\theta)\)</span></th>
<th><span class="math inline">\(b'(\theta)\equiv\mu\)</span></th>
<th><span class="math inline">\(b^{'-1}(\mu)\equiv\theta\)</span></th>
<th>Link</th>
<th>Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Normal</td>
<td><span class="math inline">\({1\over 2}\theta^2\)</span></td>
<td><span class="math inline">\(\theta\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(g(\mu)=\mu\)</span></td>
<td>Identity</td>
</tr>
<tr class="even">
<td>Poisson</td>
<td><span class="math inline">\(\exp\theta\)</span></td>
<td><span class="math inline">\(\exp\theta\)</span></td>
<td><span class="math inline">\(\log\mu\)</span></td>
<td><span class="math inline">\(g(\mu)=\log\mu\)</span></td>
<td>Log</td>
</tr>
<tr class="odd">
<td>Binomial</td>
<td><span class="math inline">\(\log(1+\exp\theta)\)</span></td>
<td><span class="math inline">\(\frac{\exp\theta}{1+\exp\theta}\)</span></td>
<td><span class="math inline">\(\log{\frac{\mu}{1-\mu}}\)</span></td>
<td><span class="math inline">\(g(\mu)=\log{\frac{\mu}{1-\mu}}\)</span></td>
<td>Logit</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="summary-1" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have introduced the components of a generalised linear model
<ul>
<li>Response distribution coming from an exponential family (<span class="alert">random component</span>).</li>
<li>Linear predictor depending on a linear combination of explanatory variables (<span class="alert">systematic component</span>).</li>
<li>Relationship between the mean <span class="math inline">\(\mu_i\)</span> and the linear predictor through the <span class="alert">link function</span>.</li>
</ul></li>
<li>We have defined the <span class="alert">canonical link function</span>, which simplifies the form of the likelihood for <span class="math inline">\(\beta\)</span>.</li>
</ul>
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.3-examples-of-glms" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.3: Examples of GLMs</h1>

</section>
<section id="recap-1" class="slide level2">
<h2>Recap</h2>
<p>A generalised linear model is a model for how the distribution of a response <span class="math inline">\(Y_i\)</span> depends on explanatory variables <span class="math inline">\(\mathbf{x}_i\)</span>. It assumes</p>
<ul>
<li>Each response <span class="math inline">\(Y_i\)</span> has the same type of distribution (a member of the exponential family), but the parameters <span class="math inline">\(\theta_i\)</span> are different for different observations <span class="math inline">\(i\)</span>.</li>
<li>The response distribution depends on the explanatory variables <span class="math inline">\(\mathbf{x}_i\)</span> through the linear predictor <span class="math inline">\(\eta_i = \mathbf{x}_i^{\top} \boldsymbol{\beta}\)</span>.</li>
<li>We have <span class="math inline">\(g(\mu_i) = \eta_i\)</span>, where <span class="math inline">\(g(\cdot)\)</span> is the link function and <span class="math inline">\(\mu_i = \mathbb{E}(Y_i)\)</span>.</li>
</ul>
</section>
<section id="glm-examples-linear-models" class="slide level2">
<h2>GLM examples: linear models</h2>
<p>In the linear model, we assume that <span class="math inline">\(Y_i \sim N(\mu_i, \sigma^2)\)</span>. We have seen already that the <span class="alert">Normal distribution is a member of the exponential family</span>.</p>
<p>The explanatory variables enter a linear model through the linear predictor <span class="math display">\[
\eta_i=\mathbf{x}_i^{\top}\boldsymbol{\beta}, \quad i = 1, \cdots, n.
\]</span></p>
<p>The link between <span class="math inline">\(\mathbb{E}(\mathbf{Y})=\boldsymbol{\mu}\)</span> and the linear predictor <span class="math inline">\(\boldsymbol{\eta}\)</span> is through the <span class="alert">(canonical) identity link function</span> <span class="math display">\[
\mu_i = \eta_i, \quad i = 1, \cdots, n.
\]</span></p>
</section>
<section id="glm-examples-binary-data" class="slide level2">
<h2>GLM examples: binary data</h2>
<div class="small-text">
<p>In binary regression, we assume either <span class="math inline">\(Y_i \sim \text{Bernoulli}(p_i)\)</span>, or <span class="math inline">\(Y_i \sim \text{Binomial}(n_i, p_i)\)</span>, where <span class="math inline">\(n_i\)</span> are known.</p>
<p>The objective is to model the success probability <span class="math inline">\(p_i\)</span> as a function of the explanatory variables <span class="math inline">\(\mathbf{x}_i\)</span>.</p>
<p>We have already seen that the <em>Bernoulli</em> and <em>Binomial</em> distributions are members of the exponential family.</p>
<div class="fragment">
<p>When the canonical (<span class="math inline">\(\text{logit}(\cdot)\)</span>) link is used, we have <span class="math display">\[
\text{logit}(p_i) = \log \left(\frac{p_i}{1-p_i}\right) = \eta_i = \mathbf{x}_i^{\top}\boldsymbol{\beta}.
\]</span> This implies <span class="math display">\[p_i = \frac{ \exp(\eta_i) }{1+ \exp(\eta_i)} = \frac{1}{1+ \exp(-\eta_i)}.\]</span> This model is known as a <span class="alert"><strong>logistic regression model</strong></span>.</p>
</div>
</div>
</section>
<section id="inverse-of-the-canonical-link-bernoulli-and-binomial-i-vevox.app-160-892-474" class="slide level2">
<h2>Inverse of the canonical link (Bernoulli and Binomial) I (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb1-2"><a href=""></a>y <span class="ot">&lt;-</span> <span class="fu">exp</span>(x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x))</span>
<span id="cb1-3"><a href=""></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Linear predictor"</span>, <span class="at">y =</span> <span class="st">"Mean (prob.)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-5-1.png" class="quarto-figure quarto-figure-center r-stretch" width="576"><p>Is this a suitable inverse link function for the Bernoulli and Binomial cases?</p>
</section>
<section id="inverse-of-the-canonical-link-bernoulli-and-binomial-ii-vevox.app-160-892-474" class="slide level2">
<h2>Inverse of the canonical link (Bernoulli and Binomial) II (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb2-2"><a href=""></a>y <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(x)</span>
<span id="cb2-3"><a href=""></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Linear predictor"</span>, <span class="at">y =</span> <span class="st">"Mean (prob.)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-6-1.png" class="quarto-figure quarto-figure-center r-stretch" width="576"><p>Is this a suitable inverse link function for the Bernoulli and Binomial cases?</p>
</section>
<section id="probit-model-bernoulli-and-binomial" class="slide level2">
<h2>Probit model (Bernoulli and Binomial)</h2>
<p>Alternatively, the <span class="alert">âprobitâ link function</span> can be used, i.e., <span class="math display">\[
g(p_i) = \Phi^{-1}(p_i)
\]</span> where <span class="math inline">\(\Phi(\cdot)\)</span> is the cumulative distribution function of a <span class="math inline">\({\text{Normal}}(0, 1)\)</span> random variable.</p>
<p>It assumes shorter tails than the logit model (i.e., probabilities in the logit model approach 0 and 1 more gradually than in probit).</p>
<div class="fragment">
<p>This means that in the <span class="alert">probit model</span> <span class="math display">\[
p_i = \Phi\left(\mathbf{x}_i^{\top}\boldsymbol{\beta}\right)~~~\text{or (equivalently)}~~~\Phi^{-1}(p_i) =\mathbf{x}_i^{\top}\boldsymbol{\beta}
\]</span> A GLM with a probit link is sometimes called a <span class="alert"><strong>probit regression model</strong></span>.</p>
</div>
</section>
<section id="inverse-of-the-canonical-link-bernoulli-and-binomial-iii-vevox.app-160-892-474" class="slide level2">
<h2>Inverse of the canonical link (Bernoulli and Binomial) III (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb3-2"><a href=""></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">exp</span>(x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x))</span>
<span id="cb3-3"><a href=""></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Linear predictor"</span>, <span class="at">y =</span> <span class="st">"Mean (prob.)"</span>) <span class="sc">+</span> <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">number_format</span>(<span class="at">accuracy =</span> <span class="fl">0.01</span>)) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-7-1.png" class="quarto-figure quarto-figure-center r-stretch" width="576"><p>Is this a suitable inverse link function for the Bernoulli and Binomial cases?</p>
</section>
<section id="inverse-of-the-canonical-link-bernoulli-and-binomial-iv-vevox.app-160-892-474" class="slide level2">
<h2>Inverse of the canonical link (Bernoulli and Binomial) IV (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb4-2"><a href=""></a>y <span class="ot">&lt;-</span> <span class="fu">exp</span>(x <span class="sc">+</span> <span class="dv">3</span>) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x <span class="sc">+</span> <span class="dv">3</span>))</span>
<span id="cb4-3"><a href=""></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Linear predictor"</span>, <span class="at">y =</span> <span class="st">"Mean (prob.)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-8-1.png" class="quarto-figure quarto-figure-center r-stretch" width="576"><p>Is this a suitable inverse link function for the Bernoulli and Binomial cases?</p>
</section>
<section id="effect-of-link-functions-in-practice" class="slide level2">
<h2>Effect of link functions in practice</h2>
<p>The choice of link function (e.g.&nbsp;between the <code>logit</code> or <code>probit</code> link) will have a large impact on the estimated parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href=""></a>beetle</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 8 Ã 5
   dose  dead alive exposed prop_killed
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;
1  1.69     6    53      59       0.102
2  1.72    13    47      60       0.217
3  1.76    18    44      62       0.290
4  1.78    28    28      56       0.5  
5  1.81    52    11      63       0.825
6  1.84    53     6      59       0.898
7  1.86    61     1      62       0.984
8  1.88    60     0      60       1    </code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb7-2"><a href=""></a><span class="fu">coef</span>(beetle_logit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)        dose 
     -60.72       34.27 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href=""></a>beetle_probit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="st">"probit"</span>), <span class="at">weights =</span> exposed)</span>
<span id="cb9-2"><a href=""></a><span class="fu">coef</span>(beetle_probit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)        dose 
     -34.94       19.73 </code></pre>
</div>
</div>
</section>
<section id="effect-of-link-functions-in-practice-1" class="slide level2">
<h2>Effect of link functions in practice</h2>
<p>However, the choice of link function (e.g.&nbsp;between the <code>logit</code> or <code>probit</code> link) often has only a small effect on the fitted success probabilities</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href=""></a>new_doses   <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">dose =</span> <span class="fu">seq</span>(<span class="fl">1.6</span>, <span class="dv">2</span>, <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb11-2"><a href=""></a>pred_logit  <span class="ot">&lt;-</span> <span class="fu">predict</span>(beetle_logit,  <span class="at">newdata =</span> new_doses, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb11-3"><a href=""></a>pred_probit <span class="ot">&lt;-</span> <span class="fu">predict</span>(beetle_probit, <span class="at">newdata =</span> new_doses, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb11-4"><a href=""></a></span>
<span id="cb11-5"><a href=""></a><span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">rep</span>(new_doses<span class="sc">$</span>dose, <span class="dv">2</span>), <span class="at">y =</span> <span class="fu">c</span>(pred_logit, pred_probit), <span class="at">link =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"Logit"</span>, <span class="st">"Probit"</span>), <span class="at">each =</span> <span class="fu">length</span>(new_doses<span class="sc">$</span>dose)))) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">colour =</span> link)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span> beetle, <span class="fu">aes</span>(<span class="at">x =</span> dose, <span class="at">y =</span> prop_killed), <span class="at">size =</span> <span class="fl">2.5</span>, <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Logit"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"Probit"</span> <span class="ot">=</span> <span class="st">"red"</span>), <span class="at">name =</span> <span class="st">"Link function"</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Dose"</span>, <span class="at">y =</span> <span class="st">"Fitted mean (prob.)"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-11-1.png" class="quarto-figure quarto-figure-center r-stretch" width="864"></section>
<section id="glm-examples-count-data" class="slide level2">
<h2>GLM examples: count data</h2>
<p>If <span class="math inline">\(Y_i\)</span> represent counts of the number of times an event occurs in a fixed time (or a fixed region of space), we might model <span class="math inline">\(Y_i \sim \text{Poisson}(\lambda_i)\)</span>.</p>
<p>We have already seen that the <span class="alert">Poisson distribution is a member of the exponential family</span>.</p>
<div class="fragment">
<p>With the canonical (<span class="math inline">\(\log(\cdot)\)</span>) link, we have <span class="math display">\[
\log \lambda_i = \eta_i = \mathbf{x}_i^{\top}\boldsymbol{\beta},
\]</span> or (equivalently) <span class="math display">\[\lambda_i = \exp\{\eta_i\} = \exp\{\mathbf{x}_i^{\top}\boldsymbol{\beta}\}.\]</span> This is often called a <span class="alert"><strong>log-linear model</strong></span> or <span class="alert"><strong>poisson regression model</strong></span></p>
</div>
</section>
<section id="poisson-regression-modelling-rates" class="slide level2">
<h2>Poisson regression (modelling rates)</h2>
<div class="small-text">
<p>Sometimes, it is more relevant to model <span class="alert">rates instead of counts</span>. This is useful, e.g., when individuals are not followed for the same amount of time (also referred to as <span class="alert"><em>exposure</em></span>).</p>
<p>Let <span class="math inline">\(E_i\)</span> be the exposure of an observation <span class="math inline">\(i\)</span>. Then, we model <span class="math inline">\(Y_i \sim \text{Poisson}(E_i\lambda_i^{*})\)</span>, where <span class="math display">\[
\log \lambda_i^{*} = \mathbf{x}_i^{\top}\boldsymbol{\beta},
\]</span></p>
<div class="fragment">
<p>Equivalently, we may define <span class="math inline">\(\lambda_i = E_i \lambda_i^*\)</span> and rewrite the model as <span class="math display">\[
Y_i \sim \text{Poisson}(\lambda_i),
\]</span> where <span id="eq-exp-poisson"><span class="math display">\[
\log \lambda_i = \log E_i + \mathbf{x}_i^{\top}\boldsymbol{\beta}
\qquad(2)\]</span></span></p>
<p>Note that <a href="#/poisson-regression-modelling-rates" class="quarto-xref">Equation&nbsp;2</a> holds since <span class="math inline">\(\lambda_i = E_i \lambda_i^*\)</span>, which implies <span class="math inline">\(\log \lambda_i = \log E_i + \log \lambda_i^*\)</span>.</p>
</div>
<div class="fragment">
<p>The log-exposure <span class="math inline">\(\log E_i\)</span> appears as a fixed term in the linear predictor (i.e., it has a coefficient of 1 in the model). Such a fixed term is called an <span class="alert"><strong>offset</strong></span>.</p>
</div>
</div>
</section>
<section id="modeling-disease-cases-adjusted-for-popul.-exposure" class="slide level2">
<h2>Modeling Disease Cases Adjusted for Popul. Exposure</h2>
<p>Assume we want to model the number of disease cases in different regions <span class="math inline">\(i\)</span> while accounting for varying population sizes. Thus, let <span class="math inline">\(Y_i\)</span> denote the number of cases in <span class="math inline">\(i\)</span>, such that <span class="math inline">\(Y_i \sim \text{Poisson}(\lambda_i)\)</span>, where <span class="math inline">\(\lambda_i = \text{pop}_i\lambda_i^*\)</span>. Also, we consider pollution levels as a potential risk factor.</p>
<div class="fragment">
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href=""></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb12-2"><a href=""></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>                                              <span class="co"># Number of regions</span></span>
<span id="cb12-3"><a href=""></a>population <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">500</span><span class="sc">:</span><span class="dv">5000</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)     <span class="co"># Population per region</span></span>
<span id="cb12-4"><a href=""></a>pollution <span class="ot">&lt;-</span>  <span class="fu">runif</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)                          <span class="co"># Pollution levels</span></span>
<span id="cb12-5"><a href=""></a></span>
<span id="cb12-6"><a href=""></a>lambda_star <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="dv">3</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> pollution)           <span class="co"># Base rate affected by pollution</span></span>
<span id="cb12-7"><a href=""></a>cases <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> population <span class="sc">*</span> lambda_star)  <span class="co"># Poisson-distributed cases</span></span>
<span id="cb12-8"><a href=""></a></span>
<span id="cb12-9"><a href=""></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">cases =</span> cases, <span class="at">population =</span> population, <span class="at">log_population =</span> <span class="fu">log</span>(population), <span class="at">pollution =</span> pollution)</span>
<span id="cb12-10"><a href=""></a><span class="fu">head</span>(data, <span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  cases population log_population pollution
1   637       1516          7.324    0.7245
2  2224       2676          7.892    0.9437
3   512       2032          7.617    0.5476
4  1154       2846          7.954    0.7117
5   139        769          6.645    0.3889
6   283       4549          8.423    0.1009</code></pre>
</div>
</div>
</div>
</section>
<section id="modeling-disease-cases-adjusted-for-popul.-exposure-1" class="slide level2">
<h2>Modeling Disease Cases Adjusted for Popul. Exposure</h2>
<div class="small-text">
<p>We can fit the Poisson regression model (with an <code>offset</code>) and plot the fitted rate (per 1,000 people) as follows</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href=""></a>poisson_mod <span class="ot">&lt;-</span> <span class="fu">glm</span>(cases <span class="sc">~</span> pollution <span class="sc">+</span> <span class="fu">offset</span>(log_population), <span class="at">family =</span> poisson, <span class="at">data =</span> data)</span>
<span id="cb14-2"><a href=""></a><span class="fu">summary</span>(poisson_mod)<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)   -2.996    0.01106  -270.9        0
pollution      2.990    0.01486   201.2        0</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href=""></a>data<span class="sc">$</span>fitted_cases <span class="ot">&lt;-</span> <span class="fu">predict</span>(poisson_mod, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb16-2"><a href=""></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> pollution, <span class="at">y =</span> cases <span class="sc">/</span> population <span class="sc">*</span> <span class="dv">1000</span>)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> fitted_cases <span class="sc">/</span> population <span class="sc">*</span> <span class="dv">1000</span>), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Pollution level"</span>, <span class="at">y =</span> <span class="st">"Cases per 1,000 people"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="chap_5_files/figure-revealjs/unnamed-chunk-14-1.png" class="quarto-figure quarto-figure-center" width="768"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="summary-2" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have reviewed GLMs, and given some commonly-used examples.</li>
<li>Next time, we will look at how to estimate the unknown parameters <span class="math inline">\(\boldsymbol{\beta}\)</span> in a GLM.</li>
</ul>
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.4-maximum-likelihood-estimation" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.4: Maximum likelihood estimation</h1>

</section>
<section id="recap-2" class="slide level2">
<h2>Recap</h2>
<ul>
<li>We have reviewed all the components of a generalised linear model, and seen how they fit together to give the overall model.</li>
<li>We have found an expression for the likelihood of the unknown regression parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>.</li>
<li>We get a much simpler expression for the likelihood if we use the canonical link function.</li>
<li>Today, we will look at finding the MLE for <span class="math inline">\(\boldsymbol{\beta}\)</span>.</li>
</ul>
</section>
<section id="components-of-a-glm" class="slide level2">
<h2>Components of a GLM</h2>
<p>As we have seen before, the components of a GLM are as follows</p>
<ul>
<li><p>The random component: in a GLM, <span class="math inline">\(Y_i\)</span> is assumed to be an independent random variable such that <span class="math display">\[\begin{equation*}
f_{Y_i}(y_i;\theta,\phi)=\exp\left({{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}} +c(y,\phi_i)\right).
\end{equation*}\]</span></p></li>
<li><p>Linear predictor: <span class="math display">\[
\eta_i = \beta_1x_{i1} + \beta_2x_{i2} + \cdots + \beta_px_{ip}.
\]</span></p></li>
<li><p>Link function: <span class="math display">\[
g(\mu_i) = \eta_i.
\]</span></p></li>
</ul>
</section>
<section id="log-likelihood-function" class="slide level2">
<h2>Log-likelihood function</h2>
<p>As usual, we maximise the log-likelihood function, which can be written as <span class="math display">\[
\ell(\boldsymbol{\beta},\boldsymbol{\phi})=
\sum_{i=1}^n{{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}}
+\sum_{i=1}^nc(y_i,\phi_i)
\]</span> and depends on <span class="math inline">\(\boldsymbol{\beta}\)</span> through <span class="math display">\[\begin{align*}
\theta_i &amp;= b^{' -1}(\mu_i), \cr
\mu_i &amp;= g^{-1}(\eta_i), \cr
\eta_i&amp;=\mathbf{x}_i^{\top}\boldsymbol{\beta}=\sum_{i=1}^p x_{ij} \beta_j, \quad i = 1, \cdots, n.
\end{align*}\]</span></p>
</section>
<section id="fitting-a-glm-in-r-from-computer-lab" class="slide level2">
<h2>Fitting a GLM in <code>R</code> (from Computer Lab)</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href=""></a>beetle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/beetle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb17-2"><a href=""></a>beetle<span class="sc">$</span>exposed     <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">+</span> beetle<span class="sc">$</span>alive</span>
<span id="cb17-3"><a href=""></a>beetle<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">/</span> beetle<span class="sc">$</span>exposed</span>
<span id="cb17-4"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb17-5"><a href=""></a></span>
<span id="cb17-6"><a href=""></a><span class="fu">summary</span>(beetle_logit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = prop_killed ~ dose, family = binomial, data = beetle, 
    weights = exposed)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -60.72       5.18   -11.7   &lt;2e-16 ***
dose           34.27       2.91    11.8   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 284.202  on 7  degrees of freedom
Residual deviance:  11.232  on 6  degrees of freedom
AIC: 41.43

Number of Fisher Scoring iterations: 4</code></pre>
</div>
</div>
</section>
<section id="general-approach-to-finding-the-mle" class="slide level2">
<h2>General approach to finding the MLE</h2>
<p>To find <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, we consider the scores <span class="math display">\[
u_k(\boldsymbol{\beta})={\partial\over{\partial\beta_k}}
\ell(\boldsymbol{\beta},\boldsymbol{\phi}), \qquad k=1,\cdots ,p
\]</span> and then find <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> to solve <span class="math inline">\(u_k(\hat{\boldsymbol{\beta}})=0\)</span> for <span class="math inline">\(k=1, \cdots ,p.\)</span></p>
</section>
<section id="score-vector" class="slide level2">
<h2>Score vector</h2>
<p>The <span class="math inline">\(k\)</span>-th component of the score vector is <span class="math display">\[\begin{align*}
u_k(\boldsymbol{\beta})&amp;= {\partial\over{\partial\beta_k}}\ell(\boldsymbol{\beta},\boldsymbol{\phi})\cr
&amp;= {\partial\over{\partial\beta_k}}\sum_{i=1}^n{{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}}
+{\partial\over{\partial\beta_k}}\sum_{i=1}^nc(y_i,\phi_i)\cr
&amp;= \sum_{i=1}^n{\partial\over{\partial\beta_k}}
\left[{{y_i\theta_i-b(\theta_i)}\over{a(\phi_i)}}\right]\cr
&amp;=\sum_{i=1}^n{\partial\over{\partial\theta_i}}\left[{{y_i\theta_i-b(\theta_i)}
\over{a(\phi_i)}}\right]{{\partial\theta_i}\over{\partial\mu_i}}
{{\partial\mu_i}\over{\partial\eta_i}}{{\partial\eta_i}\over{\partial\beta_k}}\cr
&amp;= \sum_{i=1}^n{{y_i-b'(\theta_i)}
\over{a(\phi_i)}}{{\partial\theta_i}\over{\partial\mu_i}}
{{\partial\mu_i}\over{\partial\eta_i}}{{\partial\eta_i}\over{\partial\beta_k}}, \quad{k=1,\cdots ,p}.
\end{align*}\]</span></p>
</section>
<section id="score-vector-1" class="slide level2">
<h2>Score vector</h2>
<p>We have <span class="math display">\[
u_k(\boldsymbol{\beta}) = \sum_{i=1}^n{{y_i-b'(\theta_i)}
\over{a(\phi_i)}}{{\partial\theta_i}\over{\partial\mu_i}}
{{\partial\mu_i}\over{\partial\eta_i}}{{\partial\eta_i}\over{\partial\beta_k}}, \quad{k=1,\cdots ,p},
\]</span> where <span class="math display">\[\begin{align*}
{{\partial\theta_i}\over{\partial\mu_i}}&amp;=\left[{{\partial\mu_i}\over{\partial\theta_i}}\right]^{-1}
={1\over{b''(\theta_i)}} \left(\text{ recall that } \theta_i = b^{' -1}(\mu_i) \implies \mu_i = b^{'}(\theta_i)\right) \cr
{{\partial\mu_i}\over{\partial\eta_i}}&amp;=\left[{{\partial\eta_i}\over{\partial\mu_i}}\right]^{-1}
={1\over{g'(\mu_i)}} \left(\text{ recall that } \mu_i = g^{-1}(\eta_i) \implies  \eta_i = g(\mu_i)\right) \cr
{{\partial\eta_i}\over{\partial\beta_k}}&amp;=x_{ik} \left(\text{ recall that } \eta_i=\sum_{i=1}^p x_{ij}\beta_j\right).
\end{align*}\]</span></p>
</section>
<section id="score-vector-2" class="slide level2">
<h2>Score vector</h2>
<p>Therefore <span class="math display">\[
u_k(\boldsymbol{\beta})= \sum_{i=1}^n{{y_i-b'(\theta_i)}\over{a(\phi_i)}} \cdot {{x_{ik}}\over{b''(\theta_i)g'(\mu_i)}}
=\sum_{i=1}^n{{y_i-\mu_i}\over{\text{Var}(Y_i)}} \cdot {{x_{ik}}\over{g'(\mu_i)}},
\]</span> which depends on <span class="math inline">\(\boldsymbol{\beta}\)</span> through <span class="math inline">\(\mu_i\equiv \mathbb{E}(Y_i)\)</span> and <span class="math inline">\(\text{Var}(Y_i),\)</span> <span class="math inline">\(\forall i = 1, \cdots, n\)</span>. Recall that <span class="math inline">\(\mathbb{E}(Y_i) = b^{'}(\theta_i)\)</span> and <span class="math inline">\(\text{Var}(Y_i) = a(\phi_i)b^{''}(\theta_i)\)</span>.</p>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>In theory, we solve the <span class="math inline">\(p\)</span> simultaneous equations <span class="math inline">\(u_k(\hat{\boldsymbol{\beta}})=0, ~\forall k = 1,\cdots ,p\)</span>, to evaluate <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>.</p>
<p>In practice, these equations are usually non-linear and have no analytic solution.</p>
<p>Therefore, we rely on numerical methods to solve them.</p>
</div>
</div>
</div>
</div>
</section>
<section id="numerical-methods-quiz-01-vevox.app-160-892-474" class="slide level2">
<h2>Numerical methods quiz 01 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<p>Suppose we have simple logistic regression model, with <span class="math inline">\(\eta_i = \beta\)</span>, so that we have only one parameter <span class="math inline">\(\beta\)</span> to estimate. My first guess is that <span class="math inline">\(\beta = 0\)</span>. I calculate the score there, and find <span class="math inline">\(u(0) = 2\)</span>.</p>
<p>What can I conclude about the MLE <span class="math inline">\(\hat \beta\)</span>?</p>
<ul>
<li><span class="math inline">\(\hat \beta\)</span> is less than 0.</li>
<li><span class="math inline">\(\hat \beta\)</span> is equal to 0.</li>
<li><span class="math inline">\(\hat \beta\)</span> is greater than 0.</li>
<li>It is not possible to tell.</li>
</ul>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Discussion</strong></p>
</div>
<div class="callout-content">
<p>Recall that the MLE is found by solving <span class="math display">\[
u(\hat{\beta}) = 0.
\]</span> Since <span class="math inline">\(u(0) &gt; 0\)</span>, the log-likelihood function is increasing at <span class="math inline">\(\beta = 0\)</span>. This suggests that moving to higher values of <span class="math inline">\(\beta\)</span> will continue increasing the likelihood, meaning the MLE must be greater than 0.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="numerical-methods-quiz-02-vevox.app-160-892-474" class="slide level2">
<h2>Numerical methods quiz 02 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<p>Given that <span class="math inline">\(u(0) = 2\)</span>, can I tell how close <span class="math inline">\(\hat{\beta}\)</span> is to 0?</p>
<ul>
<li><span class="math inline">\(\hat \beta\)</span> is between 0 and 1.</li>
<li><span class="math inline">\(\hat \beta\)</span> is greater than 1.</li>
<li>It is not possible to tell.</li>
</ul>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Discussion</strong></p>
</div>
<div class="callout-content">
<p>We only know that <span class="math inline">\(u(0) = 2\)</span>, but we do not know <span class="math inline">\(u'(0) \equiv H(0)\)</span>. The magnitude of <span class="math inline">\(H(0)\)</span> affects how far <span class="math inline">\(\hat{\beta}\)</span> is from 0.</p>
<ul>
<li>If <span class="math inline">\(H(0)\)</span> is large, then <span class="math inline">\(\hat{\beta}\)</span> is closer to 0.</li>
<li>If <span class="math inline">\(H(0)\)</span> is small, then <span class="math inline">\(\hat{\beta}\)</span> is further to 0.</li>
</ul>
<p>To see this, recall that near <span class="math inline">\(\beta = 0\)</span> (<em>local quadratic approximation</em>), <span class="math inline">\(\ell(\beta) \approx \ell(0) + u(0)(\beta - 0) + \frac{1}{2}H(0)(\beta - 0)^2.\)</span></p>
<p>The MLE <span class="math inline">\(\hat{\beta}\)</span> is the point where the (first) derivative of this approximation goes to zero, which leads to the Newton step <span class="math inline">\(\hat{\beta} \approx 0 - \frac{u(0)}{H(0)}\)</span>.</p>
<p>If <span class="math inline">\(â£H(0)â£\)</span> is large, you do not need to move <span class="math inline">\(\beta\)</span> very far from <span class="math inline">\(0\)</span> to get the score to zero (because the log-likelihood is <em>steeply curved</em>). Conversely, if <span class="math inline">\(â£H(0)â£\)</span> is small, you might have to move <span class="math inline">\(\beta\)</span> much farther to find the maximum.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="numerical-methods-quiz-03-vevox.app-160-892-474" class="slide level2">
<h2>Numerical methods quiz 03 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<p>Suppose I now am told that the Hessian <span class="math inline">\(H(0) = -100\)</span>.</p>
<p>Given that <span class="math inline">\(u(0) = 2\)</span> and <span class="math inline">\(H(0) = -100\)</span>, can I tell how close <span class="math inline">\(\hat{\beta}\)</span> is to 0?</p>
<ul>
<li><span class="math inline">\(\hat{\beta}\)</span> is between 0 and 1.</li>
<li><span class="math inline">\(\hat{\beta}\)</span> is greater than 1.</li>
<li>It is not possible to tell.</li>
</ul>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Discussion</strong></p>
</div>
<div class="callout-content">
<p>From quiz 02, the next <span class="math display">\[
\hat{\beta} \approx 0 - \frac{u(0)}{H(0)} = 0 + \frac{2}{100} = 0.02.
\]</span> Since <span class="math inline">\(\hat{\beta} \approx 0.02\)</span>, that is indeed positive and much less than 1. Hence, we can conclude <span class="math inline">\(\hat{\beta}\)</span> is between 0 and 1 (more precisely, fairly close to 0.02).</p>
<div class="fragment">
<p><span class="alert"><strong>Why we donât need further steps?</strong></span> For a well-behaved (smooth, concave) function like the logistic log-likelihood, the second-order (Taylor) approximation around <span class="math inline">\(\beta = 0\)</span> captures the main curvature very wellâespecially when the Hessian has large magnitude (i.e., sharply curved).</p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="numerical-example" class="slide level2">
<h2>Numerical example</h2>
<div class="small-text">
<p>Let <span class="math inline">\(Y_i \sim \text{Binomial}(m, p)\)</span>, <span class="math inline">\(\forall i = 1, \cdots, n\)</span>. Let us estimate <span class="math inline">\(p\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href=""></a>bin_loglike <span class="ot">&lt;-</span> <span class="cf">function</span>(p, y, m) { <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dbinom</span>(y, m, p))) }</span>
<span id="cb19-2"><a href=""></a>n <span class="ot">&lt;-</span> <span class="dv">20</span>; m <span class="ot">&lt;-</span> <span class="dv">10</span>; tp <span class="ot">&lt;-</span> <span class="fl">0.7</span></span>
<span id="cb19-3"><a href=""></a>y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, m, tp)</span>
<span id="cb19-4"><a href=""></a>p <span class="ot">&lt;-</span> <span class="fu">seq</span> (<span class="fl">0.05</span>, <span class="fl">0.95</span>, <span class="at">by =</span> <span class="fl">0.01</span>); </span>
<span id="cb19-5"><a href=""></a>l <span class="ot">&lt;-</span> <span class="fu">sapply</span>(p, bin_loglike, <span class="at">y =</span> y, <span class="at">m =</span> m)</span>
<span id="cb19-6"><a href=""></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> p, <span class="at">y =</span> l)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"p"</span>, <span class="at">y =</span> <span class="st">"Log-likelihood"</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="chap_5_files/figure-revealjs/unnamed-chunk-16-1.png" class="quarto-figure quarto-figure-center" width="480"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="numerical-example-1" class="slide level2">
<h2>Numerical example</h2>
<div class="small-text">
<p>Start by setting <span class="math inline">\(p^{(0)} = 0.4\)</span>. Let us compute the gradient at <span class="math inline">\(p = p^{(0)}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href=""></a>g0 <span class="ot">&lt;-</span> numDeriv<span class="sc">::</span><span class="fu">grad</span>(<span class="at">func =</span> <span class="cf">function</span>(x) { <span class="fu">bin_loglike</span>(x, y, m) }, <span class="at">x =</span> <span class="fl">0.4</span>) <span class="co"># Calculate the gradient of a function by numerical approximation at `x`</span></span>
<span id="cb20-2"><a href=""></a>g0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 262.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href=""></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> p, <span class="at">y =</span> l)) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"p"</span>, <span class="at">y =</span> <span class="st">"Log-likelihood"</span>) <span class="sc">+</span> </span>
<span id="cb22-2"><a href=""></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.4</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span> </span>
<span id="cb22-3"><a href=""></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">bin_loglike</span>(<span class="fl">0.4</span>, y, m) <span class="sc">-</span> g0 <span class="sc">*</span> <span class="fl">0.4</span>, <span class="at">slope =</span> g0) <span class="sc">+</span>  </span>
<span id="cb22-4"><a href=""></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">family =</span> <span class="st">"LM Roman 10"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="chap_5_files/figure-revealjs/unnamed-chunk-17-1.png" class="quarto-figure quarto-figure-center" width="480"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="numerical-example-2" class="slide level2">
<h2>Numerical example</h2>
<div class="small-text">
<p>Now, let us compute the Hessian at <span class="math inline">\(p = p^{(0)}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href=""></a>h0 <span class="ot">&lt;-</span> numDeriv<span class="sc">::</span><span class="fu">hessian</span>(<span class="at">func =</span> <span class="cf">function</span>(x) { <span class="fu">bin_loglike</span>(x, y, m) }, <span class="at">x =</span> <span class="fl">0.4</span>) <span class="co"># Calculate a numerical approximation to the Hessian matrix of a function at `x`.</span></span>
<span id="cb23-2"><a href=""></a>h0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]
[1,] -1052</code></pre>
</div>
</div>
<div class="fragment">
<p>We now set <span class="math display">\[
p^{(1)} = p^{(0)} + \frac{u(0.4)}{H(0.4)} = 0.4 + \frac{262.5}{1052} = 0.6495.
\]</span></p>
</div>
<div class="fragment">
<p>With one more iteration, we have</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href=""></a>g1 <span class="ot">&lt;-</span> numDeriv<span class="sc">::</span><span class="fu">grad</span>(<span class="at">func =</span> <span class="cf">function</span>(x) { <span class="fu">bin_loglike</span>(x, y, m) }, <span class="at">x =</span> <span class="fl">0.7212</span>)</span>
<span id="cb25-2"><a href=""></a>h1 <span class="ot">&lt;-</span> numDeriv<span class="sc">::</span><span class="fu">hessian</span>(<span class="at">func =</span> <span class="cf">function</span>(x) { <span class="fu">bin_loglike</span>(x, y, m) }, <span class="at">x =</span> <span class="fl">0.7212</span>)</span>
<span id="cb25-3"><a href=""></a><span class="fu">c</span>(g1, h1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]    -6.167 -1008.244</code></pre>
</div>
</div>
<p><span class="math display">\[
p^{(2)} = p^{(1)} + \frac{u(0.6495)}{H(0.6495)} = 0.6495 + \frac{57.54}{802.96} = 0.7212.
\]</span> And so onâ¦</p>
</div>
</div>
</section>
<section id="hessian-matrix" class="slide level2">
<h2>Hessian matrix</h2>
<p>The Hessian matrix has elements <span class="math display">\[
[\mathbf{H}(\boldsymbol{\beta})]_{jk}={{\partial^2}\over{\partial\beta_j\partial\beta_k}}\ell(\boldsymbol{\beta},\boldsymbol{\phi})
={\partial\over{\partial\beta_j}}u_k(\boldsymbol{\beta}),
\]</span> so <span class="math display">\[\begin{align*}
[\mathbf{H}(\boldsymbol{\beta})]_{jk}
&amp;={\partial\over{\partial\beta_j}}\sum_{i=1}^n{{y_i-\mu_i}\over{\text{Var}(Y_i)}}\cdot
{{x_{ik}}\over{g'(\mu_i)}}\cr
&amp;=\sum_{i=1}^n{{-{{\partial\mu_i}\over{\partial\beta_j}}}\over{\text{Var}(Y_i)}}\cdot
{{x_{ik}}\over{g'(\mu_i)}} +\sum_{i=1}^n(y_i-\mu_i)\cdot{\partial\over{\partial\beta_j}}
\left[{{x_{ik}}\over{\text{Var}(Y_i)
g'(\mu_i)}}\right].
\end{align*}\]</span></p>
</section>
<section id="fisher-information-matrix" class="slide level2">
<h2>Fisher information matrix</h2>
<p>The Fisher information matrix has elements</p>
<p><span class="math display">\[\begin{align*}
[{\mathcal I}(\boldsymbol{\beta})]_{jk}
&amp;=\sum_{i=1}^n{{{{\partial\mu_i}\over{\partial\beta_j}}}\over{\text{Var}(Y_i)}}\cdot
{{x_{ik}}\over{g'(\mu_i)}} -\sum_{i=1}^n(\mathbb{E}[Y_i]-\mu_i)\cdot{\partial\over{\partial\beta_j}}
\left[{{x_{ik}}\over{\text{Var}(Y_i)
g'(\mu_i)}}\right]\cr
&amp;=\sum_{i=1}^n{{{{\partial\mu_i}\over{\partial\beta_j}}}\over{\text{Var}(Y_i)}}\cdot
{{x_{ik}}\over{g'(\mu_i)}}\cr
&amp;=\sum_{i=1}^n{{x_{ij}x_{ik}}\over{\text{Var}(Y_i)g'(\mu_i)^2}} = \sum_{i=1}^n x_{ij} x_{ik} w_i,
\end{align*}\]</span> where <span class="math inline">\(w_i={1\over{\text{Var}(Y_i)g'(\mu_i)^2}},\quad i = 1, \cdots, n.\)</span></p>
</section>
<section id="a-simple-expression-for-the-fisher-information-matrix" class="slide level2">
<h2>A simple expression for the Fisher information matrix</h2>
<p>We can write <span class="math display">\[{\mathcal I}(\boldsymbol{\beta})=\mathbf{X}^{\top}\mathbf{W}\mathbf{X},\]</span> where</p>
<div class="small-text">
<p><span class="math display">\[
\mathbf{X}=\begin{pmatrix} \mathbf{x}_1^{\top}\cr\vdots\cr \mathbf{x}_n^{\top} \end{pmatrix}
=\begin{pmatrix}
x_{11}&amp;\cdots&amp;x_{1p}\cr\vdots&amp;\ddots&amp;\vdots\cr x_{n1}&amp;\cdots&amp;x_{np}
\end{pmatrix}, ~~~\text{and}~~~
\mathbf{W}={\rm diag}(\mathbf{w})=
\begin{pmatrix}
w_1&amp;0&amp;\cdots&amp;0\cr
0&amp;w_2&amp;&amp;\vdots\cr
\vdots&amp;&amp;\ddots&amp;0\cr
0&amp;\cdots&amp;0&amp;w_n
\end{pmatrix}.
\]</span></p>
</div>
<p>The Fisher information matrix <span class="math inline">\(\mathcal{I}(\boldsymbol{\beta})\)</span> depends on <span class="math inline">\(\boldsymbol{\beta}\)</span> through <span class="math inline">\(\boldsymbol{\mu}\)</span> and <span class="math inline">\(\text{Var}(Y_i),\)</span> <span class="math inline">\(\forall i = 1, \cdots, n\)</span>.</p>
</section>
<section id="a-simple-expression-for-the-score" class="slide level2">
<h2>A simple expression for the score</h2>
<p>The score may now be written as <span class="math display">\[
u_k(\boldsymbol{\beta})=\sum_{i=1}^n(y_i-\mu_i)x_{ik}w_ig'(\mu_i)
=\sum_{i=1}^n x_{ik}w_iz_i,\quad{k=1,\cdots ,p},
\]</span> where <span class="math display">\[
z_i=(y_i-\mu_i)g'(\mu_i),\quad i = 1, \cdots, n.
\]</span> Therefore <span class="math display">\[
\mathbf{u}(\boldsymbol{\beta})=\mathbf{X}^{\top}\mathbf{W}\mathbf{z}.
\]</span></p>
</section>
<section id="solving-the-score-equations-numerically" class="slide level2">
<h2>Solving the score equations numerically</h2>
<p>One possible method to solve the <span class="math inline">\(p\)</span> simultaneous equations <span class="math inline">\({\mathbf{u}}(\hat{\boldsymbol{\beta}})={\mathbf 0}\)</span> that give <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is the <span class="alert"><strong>(multivariate) Newton-Raphson method</strong></span>.</p>
<div class="fragment">
<p>If <span class="math inline">\(\boldsymbol{\beta}^{(m)}\)</span> is the current estimate of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> then the next estimate is <span class="math display">\[
\boldsymbol{\beta}^{(m+1)}=\boldsymbol{\beta}^{(m)}-\mathbf{H}(\boldsymbol{\beta}^{(m)})^{-1}\mathbf{u}(\boldsymbol{\beta}^{(m)}).
\]</span></p>
</div>
<div class="fragment">
<p>In practice, an alternative to Newton-Raphson replaces <span class="math inline">\(\mathbf{H}(\boldsymbol{\theta})\)</span> with <span class="math inline">\(\mathbb{E}[\mathbf{H}(\boldsymbol{\theta})]\equiv-\mathcal{I}(\boldsymbol{\beta})\)</span>. Therefore, if <span class="math inline">\(\boldsymbol{\beta}^{(m)}\)</span> is the current estimate of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> then the next estimate is <span class="math display">\[
\boldsymbol{\beta}^{(m+1)}=\boldsymbol{\beta}^{(m)}+{\mathcal I}(\boldsymbol{\beta}^{(m)})^{-1}\mathbf{u}(\boldsymbol{\beta}^{(m)}).
\]</span></p>
</div>
<div class="fragment">
<p>The resulting iterative algorithm is called <span class="alert"><em>Fisher scoring</em></span>.</p>
</div>
</section>
<section id="mle-for-logistic-regression-using-nlm" class="slide level2">
<h2>MLE for logistic regression using <code>nlm</code></h2>
<div class="small-text">
<p>Let <span class="math inline">\(Y_i|X_i \sim \text{Bernoulli}(p_i)\)</span>, such that <span class="math inline">\(p_i = \frac{\exp\{\beta_0 + \beta_1 X_i\}}{1 + \exp\{\beta_0 + \beta_1 X_i\}}\)</span>, <span class="math inline">\(\forall i\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href=""></a><span class="fu">set.seed</span>(<span class="dv">88</span>)</span>
<span id="cb27-2"><a href=""></a></span>
<span id="cb27-3"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>); y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="fu">exp</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x)))</span>
<span id="cb27-4"><a href=""></a>f <span class="ot">&lt;-</span> <span class="cf">function</span> (b) {</span>
<span id="cb27-5"><a href=""></a> p <span class="ot">&lt;-</span> <span class="fu">exp</span>(b[<span class="dv">1</span>] <span class="sc">+</span> (b[<span class="dv">2</span>] <span class="sc">*</span> x)) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(b[<span class="dv">1</span>] <span class="sc">+</span> (b[<span class="dv">2</span>] <span class="sc">*</span> x)))</span>
<span id="cb27-6"><a href=""></a> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">dbinom</span>(y, <span class="dv">1</span>, p, <span class="at">log =</span> <span class="cn">TRUE</span>)) <span class="co"># Negative log-likelihood</span></span>
<span id="cb27-7"><a href=""></a>}</span>
<span id="cb27-8"><a href=""></a></span>
<span id="cb27-9"><a href=""></a><span class="co"># `nlm` carries out a minimization of the function `f` using a Newton-type algorithm.</span></span>
<span id="cb27-10"><a href=""></a>ans <span class="ot">&lt;-</span> <span class="fu">nlm</span>(f, <span class="at">p =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="at">hessian =</span> <span class="cn">TRUE</span>, <span class="at">print.level =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>iteration = 0
Step:
[1] 0 0
Parameter:
[1] 0 1
Function Value
[1] 4.467
Gradient:
[1] -1.178 -1.131

iteration = 7
Parameter:
[1] 0.8751 2.1694
Function Value
[1] 3.491
Gradient:
[1] -2.220e-09 -9.007e-09

Relative gradient close to zero.
Current iterate is probably solution.</code></pre>
</div>
</div>
</div>
</section>
<section id="mle-for-logistic-regression-using-nlm-1" class="slide level2">
<h2>MLE for logistic regression using <code>nlm</code></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href=""></a>ans</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$minimum
[1] 3.491

$estimate
[1] 0.8751 2.1694

$gradient
[1] -2.220e-09 -9.007e-09

$hessian
        [,1]    [,2]
[1,]  1.0718 -0.1154
[2,] -0.1154  0.5630

$code
[1] 1

$iterations
[1] 7</code></pre>
</div>
</div>
</section>
<section id="finding-the-next-estimate-of-boldsymbolbeta" class="slide level2">
<h2>Finding the next estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span></h2>
<div class="small-text">
<p>We have <span class="math display">\[\begin{align*}
\boldsymbol{\beta}^{(m+1)}&amp;=\boldsymbol{\beta}^{(m)}+{\mathcal I}(\boldsymbol{\beta}^{(m)})^{-1}\mathbf{u}(\boldsymbol{\beta}^{(m)})\cr
&amp;=\boldsymbol{\beta}^{(m)}+[\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{X}]^{-1}\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{z}^{(m)}\cr
&amp;=[\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{X}]^{-1}[\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{X}\boldsymbol{\beta}^{(m)}+\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{z}^{(m)}]\cr
&amp;=[\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{X}]^{-1}\mathbf{X}^{\top}\mathbf{W}^{(m)}[\mathbf{X}\boldsymbol{\beta}^{(m)}+\mathbf{z}^{(m)}]\cr
&amp;=[\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{X}]^{-1}\mathbf{X}^{\top}\mathbf{W}^{(m)}[\boldsymbol{\eta}^{(m)}+\mathbf{z}^{(m)}],
\end{align*}\]</span> where <span class="math inline">\(\boldsymbol{\eta}^{(m)},\,\mathbf{W}^{(m)}\)</span> and <span class="math inline">\(\mathbf{z}^{(m)}\)</span> are all functions of <span class="math inline">\(\boldsymbol{\beta}^{(m)}\)</span>.</p>
<div class="fragment">
<p>Note that this is a weighted least squares equation; that is, <span class="math inline">\(\boldsymbol{\beta}^{(m+1)}\)</span> minimises the weighted sum of squares <span class="math display">\[
(\boldsymbol{\eta}+\mathbf{z}-\mathbf{X}\boldsymbol{\beta})^{\top}\mathbf{W}(\boldsymbol{\eta}+\mathbf{z}-\mathbf{X}\boldsymbol{\beta})=
\sum_{i=1}^n w_i\left(\eta_i+z_i-\mathbf{x}_i^{\top}\boldsymbol{\beta}\right)^2
\]</span> as a function of <span class="math inline">\(\boldsymbol{\beta}\)</span> where <span class="math inline">\(w_1,\cdots ,w_n\)</span> are the weights and <span class="math inline">\(\boldsymbol{\eta}+\mathbf{z}\)</span> is called the <span class="alert"><em>adjusted dependent variable</em></span>.</p>
</div>
</div>
</section>
<section id="fisher-scoring-algorithm" class="slide level2">
<h2>Fisher scoring algorithm</h2>
<ol type="1">
<li>Choose an initial estimate <span class="math inline">\(\boldsymbol{\beta}^{(m)}\)</span> for <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> at <span class="math inline">\(m=0\)</span>.</li>
<li>Evaluate <span class="math inline">\(\boldsymbol{\eta}^{(m)},\,\mathbf{W}^{(m)}\)</span> and <span class="math inline">\(\boldsymbol{z}^{(m)}\)</span> at <span class="math inline">\(\boldsymbol{\beta}^{(m)}\)</span>.</li>
<li>Calculate <span class="math display">\[
\boldsymbol{\beta}^{(m+1)} =[\mathbf{X}^{\top}\mathbf{W}^{(m)}\mathbf{X}]^{-1}\mathbf{X}^{\top}\mathbf{W}^{(m)}[\boldsymbol{\eta}^{(m)}+\mathbf{z}^{(m)}].
\]</span></li>
<li>If <span class="math inline">\(||\boldsymbol{\beta}^{(m+1)}-\boldsymbol{\beta}^{(m)} ||&gt; \epsilon\)</span>, for some pre-specified (small) tolerance <span class="math inline">\(\epsilon\)</span> then set <span class="math inline">\(m\to m+1\)</span> and go to 2.</li>
<li>Use <span class="math inline">\(\boldsymbol{\beta}^{(m+1)}\)</span> as the solution for <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>.</li>
</ol>
<p>As this algorithm involves iteratively minimising a weighted sum of squares, it is sometimes known as <span class="alert"><strong>iteratively reweighted least squares</strong></span>.</p>
</section>
<section id="simplification-for-the-canonical-link" class="slide level2">
<h2>Simplification for the canonical link</h2>
<p>Recall that the canonical link function is <span class="math inline">\(g(\mu)=b^{'-1}(\mu)\)</span> and with this link <span class="math inline">\(\eta_i=g(\mu_i)=\theta_i\)</span>. Then <span class="math display">\[
{1\over{g'(\mu_i)}}={{\partial\mu_i}\over{\partial\eta_i}}
={{\partial\mu_i}\over{\partial\theta_i}}=b''(\theta_i),\quad i = 1, \cdots, n.
\]</span> Therefore <span class="math inline">\(\text{Var}(Y_i)g'(\mu_i)=a(\phi_i)\)</span> which does not depend on <span class="math inline">\(\boldsymbol{\beta}\)</span>; hence, <span class="math display">\[
{\partial\over{\partial\beta_j}}\left[{{x_{ik}}\over{\text{Var}(Y_i)g'(\mu_i)}}\right]=0, \quad j=1,\cdots ,p.
\]</span></p>
<p>It follows that <span class="math inline">\(\mathbf{H}(\boldsymbol{\theta})=-\mathcal{I}(\boldsymbol{\beta})\)</span> and, for the canonical link, Newton-Raphson and Fisher scoring are equivalent.</p>
</section>
<section id="simplification-for-the-linear-model" class="slide level2">
<h2>Simplification for the linear model</h2>
<p>The linear model is a generalised linear model with identity link, <span class="math inline">\(\eta_i=g(\mu_i)=\mu_i\)</span> and <span class="math inline">\(\text{Var}(Y_i)=\sigma^2\)</span> for all <span class="math inline">\(i = 1, \cdots, n\)</span>.</p>
<p>Therefore, <span class="math display">\[
w_i=[\text{Var}(Y_i)g'(\mu_i)^2]^{-1}=\sigma^{-2} ~~~\text{and}~~~ z_i=(y_i-\mu_i)g'(\mu_i)=y_i-\eta_i,
\]</span> for <span class="math inline">\(i = 1, \cdots, n\)</span>.</p>
<p>Hence <span class="math inline">\(\mathbf{z}+\boldsymbol{\eta}=\mathbf{y}\)</span> and <span class="math inline">\(\mathbf{W}=\sigma^{-2}\mathbf{I}\)</span>, neither of which depend on <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>So the Fisher scoring algorithm converges in a single iteration to the usual least squares estimate.</p>
</section>
<section id="summary-3" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have seen how to implement the Fisher scoring algorithm: an iterative numerical method to find the MLE.</li>
<li>The likelihood is not useful only for estimating parameters. We can also use the likelihood to find (large-sample)
<ul>
<li>Confidence intervals, or to</li>
<li>Test hypotheses. We will look at this next time.</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.5-confidence-intervals" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.5: Confidence intervals</h1>

</section>
<section id="recap-3" class="slide level2">
<h2>Recap</h2>
<ul>
<li>We have seen how to find the MLE for <span class="math inline">\(\boldsymbol{\beta}\)</span>.</li>
<li>Today, we will look at computing confidence intervals and test hypotheses.</li>
</ul>
</section>
<section id="asymptotic-distribution-of-hatboldsymbolbeta" class="slide level2">
<h2>Asymptotic distribution of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span></h2>
<p>We are not just interested in finding an estimate of <span class="math inline">\(\boldsymbol\beta\)</span>; we might also want to quantify the uncertainty in our estimate.</p>
<p>To do so, we can use the general asymptotic results about the MLE.</p>
<p>Recall that <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> has asymptotic <span class="math display">\[\text{Normal}(\boldsymbol{\beta}, {\mathcal{I}}(\boldsymbol{\beta})^{-1})\]</span> distribution; i.e., it is unbiased (Chapter 2).</p>
</section>
<section id="standard-errors" class="slide level2">
<h2>Standard errors</h2>
<p>Therefore, standard errors (estimated standard deviations) are given by <span class="math display">\[
\text{SE}(\hat{\beta}_i)=[{\mathcal I}(\hat{\boldsymbol{\beta}})^{-1}]_{ii}^{{1\over 2}}
=[(\mathbf{X}^{\top}\hat{\mathbf{W}}\mathbf{X})^{-1}]_{ii}^{{1\over 2}}
\qquad i=1,\cdots ,p.
\]</span> where the diagonal matrix <span class="math inline">\(\hat{\mathbf{W}}={\rm diag}(\hat{\mathbf{w}})\)</span> is evaluated at <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, that is <span class="math inline">\(\hat{w}_i=(\hat{\text{Var}}(Y_i)g'(\hat{\mu}_i)^2)^{-1}\)</span> where <span class="math inline">\(\hat{\mu}_i\)</span> and <span class="math inline">\(\hat{\text{Var}}(Y_i)\)</span> are evaluated at <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> for <span class="math inline">\(i = 1, \cdots, n\)</span>.</p>
<p>If <span class="math inline">\(\text{Var}(Y_i)\)</span> depends on an unknown scale parameter, then this too must be estimated in the standard error.</p>
</section>
<section id="large-sample-confidence-intervals" class="slide level2">
<h2>Large sample confidence intervals</h2>
<div class="small-text">
<p>For large <span class="math inline">\(n\)</span>, we have (approximately) <span class="math inline">\(\hat{\boldsymbol\beta} \sim {\text{Normal}}(\boldsymbol{\beta}, {\mathcal{I}}(\boldsymbol{\beta})^{-1})\)</span>.</p>
<p>For a given <span class="math inline">\(\alpha\)</span>, we can find <span class="math inline">\(z_{1-\frac{\alpha}{2}}\)</span>, such that <span class="math display">\[
P\left(-z_{1-\frac{\alpha}{2}}\le {{\hat{\beta}_i-\beta_i}\over{[\mathcal{I}(\boldsymbol{\beta})^{-1}]_{ii}^{1\over 2}}}\le
z_{1-\frac{\alpha}{2}}\right) =1-\alpha.
\]</span></p>
<div class="fragment">
<p>Therefore, <span class="math display">\[
P\left(\hat{\beta}_i-z_{1-\frac{\alpha}{2}}[\mathcal{I}(\boldsymbol{\beta})^{-1}]_{ii}^{1\over 2}\le\beta_i
\le\hat{\beta}_i+z_{1-\frac{\alpha}{2}}[\mathcal{I}(\boldsymbol{\beta})^{-1}]_{ii}^{1\over 2}
\right) =1-\alpha.
\]</span> The endpoints of this interval cannot be evaluated because they also depend on the unknown parameter vector <span class="math inline">\(\boldsymbol{\beta}\)</span>. However, if we replace <span class="math inline">\({\mathcal{I}}(\boldsymbol{\beta})\)</span> by its MLE <span class="math inline">\({\mathcal{I}}(\hat{\boldsymbol{\beta}})\)</span>, we obtain the approximate large sample <span class="math inline">\(100\cdot(1-\alpha)\%\)</span> confidence interval <span class="math display">\[
\left[\hat{\beta}_i-\text{SE}(\hat{\beta}_i)z_{1-\frac{\alpha}{2}}\,,\,
\hat{\beta}_i+\text{SE}(\hat{\beta}_i)z_{1-\frac{\alpha}{2}}\right].
\]</span></p>
</div>
</div>
</section>
<section id="hypothesis-testing-single-parameter-case" class="slide level2">
<h2>Hypothesis testing: single parameter case</h2>
<p>Suppose we want to test the hypothesis <span class="math inline">\(H_0: \beta_j = 0\)</span> against the alternative <span class="math inline">\(H_1: \text{$\beta_j$ is unrestricted}\)</span>, for a single component <span class="math inline">\(\beta_j\)</span> of <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>Under <span class="math inline">\(H_0\)</span>, for large samples, we have approximately <span class="math display">\[
z = \frac{\hat \beta_j - 0}{\text{SE}(\hat \beta_j)} \sim \text{Normal}(0, 1),
\]</span> so we reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|z|\)</span> exceeds the critical value <span class="math inline">\(z_{1 - \frac{\alpha}{2}}\)</span> from the standard normal distribution.</p>
</section>
<section id="a-redacted-summary-01-vevox.app-160-892-474" class="slide level2">
<h2>A redacted <code>summary</code> 01 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href=""></a>beetle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/beetle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb31-2"><a href=""></a>beetle<span class="sc">$</span>exposed     <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">+</span> beetle<span class="sc">$</span>alive</span>
<span id="cb31-3"><a href=""></a>beetle<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">/</span> beetle<span class="sc">$</span>exposed</span>
<span id="cb31-4"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb31-5"><a href=""></a>summary_mod <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(<span class="fu">summary</span>(beetle_logit))</span>
<span id="cb31-6"><a href=""></a>summary_mod[<span class="dv">8</span>] <span class="ot">&lt;-</span> <span class="st">"(Intercept)  -60.717      5.181   [ A ]   -----"</span></span>
<span id="cb31-7"><a href=""></a>summary_mod[<span class="dv">9</span>] <span class="ot">&lt;-</span> <span class="st">"dose          34.270      [ B ]   11.77   [ C ]"</span></span>
<span id="cb31-8"><a href=""></a><span class="fu">cat</span>(summary_mod[<span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>], <span class="at">fill =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call: 
glm(formula = prop_killed ~ dose, family = binomial, data = beetle,  
    weights = exposed) 
 
Coefficients: 
            Estimate Std. Error z value Pr(&gt;|z|)     
(Intercept)  -60.717      5.181   [ A ]   ----- 
dose          34.270      [ B ]   11.77   [ C ] 
---</code></pre>
</div>
</div>
<p>What is the value <span class="math inline">\(\text{A}\)</span> here?</p>
<ul>
<li><span class="math inline">\(-20.32\)</span></li>
<li><span class="math inline">\(-11.72\)</span></li>
<li><span class="math inline">\(1.96\)</span></li>
<li><span class="math inline">\(11.72\)</span></li>
<li><span class="math inline">\(20.32\)</span></li>
</ul>
</div>
</section>
<section id="a-redacted-summary-02-vevox.app-160-892-474" class="slide level2">
<h2>A redacted <code>summary</code> 02 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href=""></a>beetle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/beetle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb33-2"><a href=""></a>beetle<span class="sc">$</span>exposed     <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">+</span> beetle<span class="sc">$</span>alive</span>
<span id="cb33-3"><a href=""></a>beetle<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">/</span> beetle<span class="sc">$</span>exposed</span>
<span id="cb33-4"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb33-5"><a href=""></a>summary_mod <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(<span class="fu">summary</span>(beetle_logit))</span>
<span id="cb33-6"><a href=""></a>summary_mod[<span class="dv">8</span>] <span class="ot">&lt;-</span> <span class="st">"(Intercept)  -60.717      5.181   [ A ]   -----"</span></span>
<span id="cb33-7"><a href=""></a>summary_mod[<span class="dv">9</span>] <span class="ot">&lt;-</span> <span class="st">"dose          34.270      [ B ]   11.77   [ C ]"</span></span>
<span id="cb33-8"><a href=""></a><span class="fu">cat</span>(summary_mod[<span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>], <span class="at">fill =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call: 
glm(formula = prop_killed ~ dose, family = binomial, data = beetle,  
    weights = exposed) 
 
Coefficients: 
            Estimate Std. Error z value Pr(&gt;|z|)     
(Intercept)  -60.717      5.181   [ A ]   ----- 
dose          34.270      [ B ]   11.77   [ C ] 
---</code></pre>
</div>
</div>
<p>What is the value <span class="math inline">\(\text{B}\)</span> here?</p>
<ul>
<li><span class="math inline">\(-5.181\)</span></li>
<li><span class="math inline">\(-2.912\)</span></li>
<li><span class="math inline">\(1.96\)</span></li>
<li><span class="math inline">\(2.912\)</span></li>
<li><span class="math inline">\(5.181\)</span></li>
</ul>
</div>
</section>
<section id="a-redacted-summary-03-vevox.app-160-892-474" class="slide level2">
<h2>A redacted <code>summary</code> 03 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href=""></a>beetle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/beetle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb35-2"><a href=""></a>beetle<span class="sc">$</span>exposed     <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">+</span> beetle<span class="sc">$</span>alive</span>
<span id="cb35-3"><a href=""></a>beetle<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">/</span> beetle<span class="sc">$</span>exposed</span>
<span id="cb35-4"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb35-5"><a href=""></a>summary_mod <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(<span class="fu">summary</span>(beetle_logit))</span>
<span id="cb35-6"><a href=""></a>summary_mod[<span class="dv">8</span>] <span class="ot">&lt;-</span> <span class="st">"(Intercept)  -60.717      5.181   [ A ]   -----"</span></span>
<span id="cb35-7"><a href=""></a>summary_mod[<span class="dv">9</span>] <span class="ot">&lt;-</span> <span class="st">"dose          34.270      [ B ]   11.77   [ C ]"</span></span>
<span id="cb35-8"><a href=""></a><span class="fu">cat</span>(summary_mod[<span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>], <span class="at">fill =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call: 
glm(formula = prop_killed ~ dose, family = binomial, data = beetle,  
    weights = exposed) 
 
Coefficients: 
            Estimate Std. Error z value Pr(&gt;|z|)     
(Intercept)  -60.717      5.181   [ A ]   ----- 
dose          34.270      [ B ]   11.77   [ C ] 
---</code></pre>
</div>
</div>
<p>Which of the following would calculate <span class="math inline">\(\text{C}\)</span> correctly?</p>
<ul>
<li><code>pnorm(11.77)</code></li>
<li><code>1 - pnorm(11.77)</code></li>
<li><code>2 * pnorm(11.77)</code></li>
<li><code>2 * (1 - pnorm(11.77))</code></li>
</ul>
</div>
</section>
<section id="a-redacted-summary-04-vevox.app-160-892-474" class="slide level2">
<h2>A redacted <code>summary</code> 04 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href=""></a>beetle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/beetle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb37-2"><a href=""></a>beetle<span class="sc">$</span>exposed     <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">+</span> beetle<span class="sc">$</span>alive</span>
<span id="cb37-3"><a href=""></a>beetle<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">/</span> beetle<span class="sc">$</span>exposed</span>
<span id="cb37-4"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb37-5"><a href=""></a>summary_mod <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(<span class="fu">summary</span>(beetle_logit))</span>
<span id="cb37-6"><a href=""></a><span class="fu">cat</span>(summary_mod[<span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>], <span class="at">fill =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call: 
glm(formula = prop_killed ~ dose, family = binomial, data = beetle,  
    weights = exposed) 
 
Coefficients: 
            Estimate Std. Error z value Pr(&gt;|z|)     
(Intercept)   -60.72       5.18   -11.7   &lt;2e-16 *** 
dose           34.27       2.91    11.8   &lt;2e-16 *** 
---</code></pre>
</div>
</div>
<p>Which of the following is a <span class="math inline">\(95\%\)</span> confidence interval for <span class="math inline">\(\beta_2\)</span>, i.e., the coefficient for <code>dose</code> in the <code>beetle_logit</code> model?</p>
<ul>
<li><span class="math inline">\((11.2, 57.3)\)</span></li>
<li><span class="math inline">\((28.6, 40.0)\)</span></li>
<li><span class="math inline">\((31.4, 37.2)\)</span></li>
</ul>
</div>
</section>
<section id="summary-4" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have seen how to use general asymptotic results about the MLE to
<ul>
<li>Compute standard errors of estimates</li>
<li>Compute confidence intervals,</li>
<li>Test the hypothesis that <span class="math inline">\(\beta_j = 0\)</span> (for a single parameter <span class="math inline">\(\beta_j\)</span>).</li>
</ul></li>
<li>Next time, we will look at testing more general hypotheses in a GLM.</li>
</ul>
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.6-comparing-glms" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.6: Comparing GLMs</h1>

</section>
<section id="recap-4" class="slide level2">
<h2>Recap</h2>
<ul>
<li>We have seen how to use general asymptotic results about the MLE to find standard errors of estimates, find confidence intervals, and test the hypothesis that <span class="math inline">\(\beta_j = 0\)</span>, for a single parameter <span class="math inline">\(\beta_j\)</span>.</li>
<li>Now we will look at testing more general hypotheses in a GLM, using our general theory about log likelihood ratio tests.</li>
<li>We will also look at a test of whether the model appears to fit the data (goodness of fit).</li>
</ul>
</section>
<section id="comparing-candidate-models" class="slide level2">
<h2>Comparing candidate models</h2>
<p>If we have a set of competing GLMs which might explain the dependence of the response on the explanatory variables, we will want to determine which of the models is most appropriate.</p>
<p>As with linear models, we proceed, e.g., by comparing models pairwise using a <span class="alert"><strong>generalised likelihood ratio test</strong></span>.</p>
<p>This is restricted to situations where one of the models <span class="math inline">\((H_0)\)</span> is <strong>nested</strong> in the other <span class="math inline">\((H_1)\)</span>.</p>
<div class="fragment">
<p>For generalised linear models, âânestedââ means that <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> are</p>
<ol type="1">
<li>Based on the same exponential family distribution, and</li>
<li>Have the same link function, but</li>
<li>The explanatory variables present in <span class="math inline">\(H_0\)</span> are a subset of those in <span class="math inline">\(H_1\)</span>.</li>
</ol>
</div>
</section>
<section id="model-setup" class="slide level2">
<h2>Model setup</h2>
<p>We will assume that model <span class="math inline">\(H_1\)</span> contains <span class="math inline">\(p\)</span> linear parameters and model <span class="math inline">\(H_0\)</span> a subset of <span class="math inline">\(q &lt; p\)</span> of these. Without loss of generality, we can think of <span class="math inline">\(H_1\)</span> as the model <span class="math display">\[
\eta_i=\sum_{j=1}^p x_{ij} \beta_j \qquad i = 1, \cdots, n
\]</span> and <span class="math inline">\(H_0\)</span> is the same model with <span class="math display">\[
\beta_{q+1}=\beta_{q+2}=\cdots=\beta_p=0.
\]</span></p>
<p>Then model <span class="math inline">\(H_0\)</span> is a special case of model <span class="math inline">\(H_1\)</span>, where certain coefficients are set equal to zero, and therefore <span class="math inline">\(\Theta^{(0)}\)</span> (the set of values of the canonical parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> allowed by <span class="math inline">\(H_0\)</span>) is a subset of <span class="math inline">\(\Theta^{(1)}\)</span> (the set of values allowed by <span class="math inline">\(H_1\)</span>).</p>
</section>
<section id="log-likelihood-ratio-statistic" class="slide level2">
<h2>Log-likelihood ratio statistic</h2>
<div class="small-text">
<p>The log-likelihood ratio statistic for a test of <span class="math inline">\(H_0\)</span> against <span class="math inline">\(H_1\)</span> is <span class="math display">\[
L_{01} \equiv 2\log \left({{\max_{\boldsymbol{\theta}\in \Theta^{(1)}} \mathcal{L}(\boldsymbol{\theta})}\over
{\max_{\boldsymbol{\theta}\in \Theta^{(0)}}\mathcal{L}(\boldsymbol{\theta})}}\right)
=2\log\mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(1)}\right)-2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(0)}\right),
\]</span> where <span class="math display">\[
\hat \theta^{(j)} = b^{'-1}\left(g^{-1}\left(\mathbf{x}_i^{\top}\hat{\boldsymbol \beta}^{(j)}\right)\right), \quad j \in \{0, 1\},
\]</span> and <span class="math inline">\(\hat{\boldsymbol{\beta}}^{(j)}\)</span> is the MLE of <span class="math inline">\(\boldsymbol{\beta}\)</span> under model <span class="math inline">\(j\)</span>.</p>
<p>Here we assume that <span class="math inline">\(a(\phi_i),\;i = 1, \cdots, n\)</span>, are known.</p>
<div class="fragment">
<p>We reject <span class="math inline">\(H_0\)</span> in favour of <span class="math inline">\(H_1\)</span> when <span class="math inline">\(L_{01}\)</span> is <em>too large</em> (i.e., the observed data are much more probable under <span class="math inline">\(H_1\)</span> than <span class="math inline">\(H_0\)</span>).</p>
<p>Asymptotically, under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(L_{01} \sim \chi^2_{(p-q)}\)</span>, so we reject <span class="math inline">\(H_0\)</span> in favour of <span class="math inline">\(H_1\)</span> when <span class="math inline">\(L_{01}\)</span> is greater than the <span class="math inline">\(100\cdot(1- \alpha)\%\)</span> point of the <span class="math inline">\(\chi^2_{p-q}\)</span> distribution.</p>
</div>
</div>
</section>
<section id="comparing-models-in-r-01-vevox.app-160-892-474" class="slide level2">
<h2>Comparing models in <code>R</code> 01 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href=""></a>shuttle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/shuttle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb39-2"><a href=""></a>shuttle<span class="sc">$</span>n <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">6</span>, <span class="fu">nrow</span>(shuttle))</span>
<span id="cb39-3"><a href=""></a><span class="fu">head</span>(shuttle)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 Ã 5
  n_damaged  temp pressure orbiter        n
      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;
1         2    53      200 Discovery      6
2         1    57      200 Challenger     6
3         1    58      200 Columbia       6
4         1    63      200 Challenger     6
5         0    66       50 Columbia       6
6         0    67      200 Discovery      6</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href=""></a>shuttle_glm0 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp,           <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span>
<span id="cb41-2"><a href=""></a>shuttle_glm1 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp <span class="sc">+</span> orbiter, <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here <code>temp</code> is a continuous variable, and <code>orbiter</code> is a factor with <span class="math inline">\(4\)</span> levels. What is <span class="math inline">\(q\)</span> (the number of parameters in <span class="alert"><code>shuttle_glm0</code></span>)?</p>
<ul>
<li>1</li>
<li>2</li>
<li>3</li>
<li>4</li>
<li>5</li>
<li>6</li>
</ul>
</div>
</section>
<section id="comparing-models-in-r-02-vevox.app-160-892-474" class="slide level2">
<h2>Comparing models in <code>R</code> 02 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href=""></a>shuttle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/shuttle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb42-2"><a href=""></a>shuttle<span class="sc">$</span>n <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">6</span>, <span class="fu">nrow</span>(shuttle))</span>
<span id="cb42-3"><a href=""></a><span class="fu">head</span>(shuttle)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 Ã 5
  n_damaged  temp pressure orbiter        n
      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;
1         2    53      200 Discovery      6
2         1    57      200 Challenger     6
3         1    58      200 Columbia       6
4         1    63      200 Challenger     6
5         0    66       50 Columbia       6
6         0    67      200 Discovery      6</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href=""></a>shuttle_glm0 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp,           <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span>
<span id="cb44-2"><a href=""></a>shuttle_glm1 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp <span class="sc">+</span> orbiter, <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here <code>temp</code> is a continuous variable, and <code>orbiter</code> is a factor with <span class="math inline">\(4\)</span> levels. What is <span class="math inline">\(p\)</span> (the number of parameters in <span class="alert"><code>shuttle_glm1</code></span>)?</p>
<ul>
<li>1</li>
<li>2</li>
<li>3</li>
<li>4</li>
<li>5</li>
<li>6</li>
</ul>
</div>
</section>
<section id="comparing-models-in-r-03-vevox.app-160-892-474" class="slide level2">
<h2>Comparing models in <code>R</code> 03 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<p>Now, we conduct a log likelihood ratio test to compare the two models.</p>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href=""></a><span class="fu">anova</span>(shuttle_glm0, shuttle_glm1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: (n_damaged/n) ~ temp
Model 2: (n_damaged/n) ~ temp + orbiter
  Resid. Df Resid. Dev Df Deviance
1        21       18.1            
2        18       17.1  3     1.02</code></pre>
</div>
</div>
<div class="small-text">
<p>Here <span class="math inline">\(L_{01}\)</span> is <span class="math inline">\(1.02\)</span> (given in the deviance column).</p>
<p>Under <span class="math inline">\(H_0\)</span>, what is the (asymptotic) distribution of <span class="math inline">\(L_{01}\)</span>?</p>
<ul>
<li><span class="math inline">\(\chi^2_1\)</span></li>
<li><span class="math inline">\(\chi^2_3\)</span></li>
<li><span class="math inline">\(\chi^2_{18}\)</span></li>
<li><span class="math inline">\(\chi^2_{21}\)</span></li>
</ul>
</div>
</section>
<section id="comparing-models-in-r-04-vevox.app-160-892-474" class="slide level2">
<h2>Comparing models in <code>R</code> 04 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<p>Next, we aim to compute the critical value.</p>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href=""></a><span class="fu">anova</span>(shuttle_glm0, shuttle_glm1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: (n_damaged/n) ~ temp
Model 2: (n_damaged/n) ~ temp + orbiter
  Resid. Df Resid. Dev Df Deviance
1        21       18.1            
2        18       17.1  3     1.02</code></pre>
</div>
</div>
<div class="small-text">
<p>We should reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(L_{01} &gt; k\)</span>. Which of the following commands could be used to find <span class="math inline">\(k\)</span>, for a test at the <span class="math inline">\(5\%\)</span> level?</p>
<ul>
<li><code>dchisq(0.95, df = 3)</code></li>
<li><code>pchisq(0.95, df = 3)</code></li>
<li><code>qchisq(0.95, df = 3)</code></li>
</ul>
</div>
</section>
<section id="comparing-models-in-r-05-vevox.app-160-892-474" class="slide level2">
<h2>Comparing models in <code>R</code> 05 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="small-text">
<p>Lastly, we aim to compute the <span class="math inline">\(p\)</span>-value.</p>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: (n_damaged/n) ~ temp
Model 2: (n_damaged/n) ~ temp + orbiter
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
1        21       18.1                     
2        18       17.1  3     1.02      0.8</code></pre>
</div>
</div>
<div class="small-text">
<p>The final column gives a <span class="math inline">\(p\)</span>-value: the probability that <span class="math inline">\(L_{01} \geq 1.0238\)</span>, if <span class="math inline">\(H_0\)</span> is true. Here the <span class="math inline">\(p\)</span>-value is <span class="math inline">\(0.7955\)</span>, so we do not reject <span class="math inline">\(H_0\)</span>.</p>
<p>Which of the following commands could be used to find the <span class="math inline">\(p\)</span>-value?</p>
<ul>
<li><code>dchisq(1.0238, df = 3)</code></li>
<li><code>1 - dchisq(1.0238, df = 3)</code></li>
<li><code>pchisq(1.0238, df = 3)</code></li>
<li><code>1 - pchisq(1.0238, df = 3)</code></li>
<li><code>qchisq(1.0238, df = 3)</code></li>
<li><code>1 - qchisq(1.0238, df = 3)</code></li>
</ul>
</div>
</section>
<section id="the-saturated-model" class="slide level2">
<h2>The saturated model</h2>
<p>Consider a model where <span class="math inline">\(\boldsymbol{\beta}\)</span> is <span class="math inline">\(n\)</span>-dimensional. Assuming that <span class="math inline">\(\mathbf{X}\)</span> is invertible, then this model places no constraints on the linear predictor <span class="math inline">\(\boldsymbol{\eta} = (\eta_1, \cdots ,\eta_n)\)</span>. <span class="alert">This means the model has complete flexibility to fit every observed data point exactly.</span></p>
<p>Correspondingly, the means <span class="math inline">\(\boldsymbol{\mu}\)</span> and the canonical parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> are unconstrained.</p>
<p>The model is of dimension <span class="math inline">\(n\)</span> and can be parameterised equivalently using <span class="math inline">\(\boldsymbol{\beta}\)</span>, <span class="math inline">\(\boldsymbol{\eta}\)</span>, <span class="math inline">\(\boldsymbol{\mu}\)</span> or <span class="math inline">\(\boldsymbol{\theta}\)</span>. Such a model is called the <span class="alert"><strong>saturated model</strong></span>.</p>
</section>
<section id="mle-in-the-saturated-model" class="slide level2">
<h2>MLE in the saturated model</h2>
<div class="small-text">
<p>As the canonical parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> are unconstrained, we can calculate their maximum likelihood estimates <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> directly from their likelihood (without first having to calculate <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>) <span class="math display">\[
\ell(\boldsymbol{\theta})=\sum_{i=1}^n{{y_i\theta_i-b(\theta_i)}
\over{a(\phi_i)}}+\sum_{i=1}^nc(y_i,\phi_i).
\]</span></p>
<div class="fragment">
<p>We obtain <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> by first differentiating with respect to <span class="math inline">\(\theta_1,\cdots ,\theta_n\)</span> to give <span class="math display">\[
u_k(\boldsymbol \theta) = {\partial\over{\partial\theta_k}}\ell(\boldsymbol{\theta})={{y_k-b'(\theta_k)}
\over{a(\phi_k)}},\quad k=1,\cdots ,n.
\]</span> So, setting the score function to zero, we have <span class="math display">\[
b'(\hat{\theta}_k)=y_k, \quad k=1,\cdots, n.
\]</span> Since <span class="math inline">\(b'(\theta_k)\)</span> gives the expected value of the response, we have that <span class="math inline">\(\hat{\mu}_k=b'(\hat{\theta}_k) = y_k,\; \forall k\)</span>.</p>
</div>
<div class="fragment">
<p>This means that the saturated model fit the data perfectly, as the <strong>fitted values</strong> <span class="math inline">\(\hat{\mu}_k\)</span> and observed values <span class="math inline">\(y_k\)</span> are the same for every observation <span class="math inline">\(k=1,\cdots ,n\)</span>.</p>
</div>
</div>
</section>
<section id="using-the-saturated-model-to-check-goodness-of-fit" class="slide level2">
<h2>Using the saturated model to check goodness of fit</h2>
<p>The saturated model is rarely of any scientific interest in its own right. It is highly parameterised, such that <span class="math inline">\(n = p\)</span>.</p>
<p>However, every other model is nested in the saturated model, and a test comparing a model <span class="math inline">\(H_0\)</span> against the saturated model <span class="math inline">\(H_S\)</span> can be used as a <span class="alert">goodness of fit test</span>.</p>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>If the saturated model, which fits the observed data perfectly, does not provide a significantly better fit than model <span class="math inline">\(H_0\)</span>, we can conclude that <span class="math inline">\(H_0\)</span> is an acceptable fit to the data.</p>
</div>
</div>
</div>
</div>
</section>
<section id="testing-h_0-against-h_s" class="slide level2">
<h2>Testing <span class="math inline">\(H_0\)</span> against <span class="math inline">\(H_S\)</span></h2>
<p>The log likelihood ratio statistic for a test of <span class="math inline">\(H_0\)</span> against <span class="math inline">\(H_S\)</span> is <span class="math display">\[
L_{0s}=2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(s)}\right)-2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(0)}\right),
\]</span> where <span class="math inline">\(\hat \theta^{(s)}_k = (b')^{-1}(y_k)\)</span>.</p>
<div class="fragment">
<p>Under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(L_{0s}\)</span> has an asymptotic <span class="math inline">\(\chi^2_{(n-q)}\)</span> distribution.</p>
</div>
<div class="fragment">
<p>Therefore, if <span class="math inline">\(L_{0s}\)</span> is ââtoo largeââ (for example, larger than the 95% point of the <span class="math inline">\(\chi^2_{(n-q)}\)</span> distribution), then we reject <span class="math inline">\(H_0\)</span> as a plausible model for the data (as it does not fit the data adequately).</p>
</div>
</section>
<section id="the-scaled-deviance" class="slide level2">
<h2>The scaled deviance</h2>
<p>We call <span class="math inline">\(L_{0s}\)</span> the <strong>scaled deviance</strong> (<code>R</code> calls it the <strong>residual deviance</strong>) of model <span class="math inline">\(H_0\)</span>.</p>
<p>We can write the scaled deviance of model <span class="math inline">\(H_0\)</span> as <span class="math inline">\(\left(\text{recall that }L_{0s}=2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(s)}\right)-2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(0)}\right)\right)\)</span> <span class="math display">\[
L_{0s}=2\sum_{i=1}^n{{y_i[\hat{\theta}^{(s)}_i-\hat{\theta}^{(0)}_i]
-[b(\hat{\theta}^{(s)}_i)-b(\hat{\theta}^{(0)}_i)]}
\over{a(\phi_i)}},
\]</span> which can be calculated using the observed data, provided that <span class="math inline">\(a(\phi_i),\;
i = 1, \cdots, n\)</span>, is known.</p>
</section>
<section id="scaled-deviance-in-r" class="slide level2">
<h2>Scaled deviance in <code>R</code></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href=""></a><span class="fu">summary</span>(shuttle_glm0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = (n_damaged/n) ~ temp, family = binomial, data = shuttle, 
    weights = n)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)    5.085      3.053    1.67    0.096 .
temp          -0.116      0.047   -2.46    0.014 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 24.230  on 22  degrees of freedom
Residual deviance: 18.086  on 21  degrees of freedom
AIC: 35.65

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
<div class="small-text">
<p>For the model <code>shuttle_glm0</code>, the scaled (or ââresidualââ) deviance is <span class="math inline">\(18.086\)</span> on <span class="math inline">\(21\)</span> degrees of freedom.</p>
<div class="fragment">
<p>As a note, the <strong>Null deviance</strong> compares the saturated model against the intercept-only model.</p>
</div>
</div>
</section>
<section id="interpreting-the-scaled-deviance" class="slide level2">
<h2>Interpreting the scaled deviance</h2>
<p>For the model <code>shuttle_glm0</code>, the scaled deviance (called ââresidual devianceââ in <code>R</code>) is <span class="math inline">\(18.086\)</span> on <span class="math inline">\(21\)</span> degrees of freedom.</p>
<p>We have</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href=""></a><span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">21</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 32.67</code></pre>
</div>
</div>
<p>which is greater than <span class="math inline">\(18.086\)</span>.</p>
<div class="fragment">
<p>The value of the scaled deviance is consistent with the model <code>shuttle_glm0</code>, and does not cause us to be concerned about lack of fit to the data.</p>
<p>Alternatively, <span class="alert">at the <span class="math inline">\(5\%\)</span> level, the deviance suggests no significant lack of fit, so we fail to reject the null hypothesis that the model is correct</span>.</p>
</div>
</section>
<section id="summary-5" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have used the general results about the asymptotic distribution of the log-likelihood ratio statistic to conduct generalised likelihood ratio tests for GLMs.</li>
<li>We have seen how to use the scaled (or ââresidualââ) deviance as a goodness of fit test.</li>
<li>Next time, we will see how to use the scaled deviance to calculate log-likelihood ratio statistics, and look at an alternative measure of model fit.</li>
<li>We will also look at what happens when <span class="math inline">\(a(\phi)\)</span> is unknown.</li>
</ul>
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.7-deviance" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.7: Deviance</h1>

</section>
<section id="recap-5" class="slide level2">
<h2>Recap</h2>
<p>The general results about the asymptotic distribution of the log likelihood ratio statistic allow us to conduct generalised likelihood ratio tests for GLMs.</p>
<p>The <strong>scaled deviance</strong> <span class="math inline">\(L_{0S}\)</span> is the log-likelihood ratio statistic for comparing any model <span class="math inline">\(H_0\)</span> against the saturated model <span class="math inline">\(H_S\)</span> <span class="math display">\[
L_{0s}=2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(s)}\right)-2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(0)}\right).
\]</span></p>
</section>
<section id="comparing-models-using-the-scaled-deviance" class="slide level2">
<h2>Comparing models using the scaled deviance</h2>
<p>The log likelihood ratio statistic for testing <span class="math inline">\(H_0\)</span> against a non-saturated alternative <span class="math inline">\(H_1\)</span> can be written as</p>
<p><span class="math display">\[\begin{align*}
L_{01}&amp;=2\log \mathcal{L}(\hat{\boldsymbol{\theta}}^{(1)})-2\log \mathcal{L}(\hat{\boldsymbol{\theta}}^{(0)})\cr
&amp;=[2\log \mathcal{L}(\hat{\boldsymbol{\theta}}^{(s)})-2\log \mathcal{L}(\hat{\boldsymbol{\theta}}^{(0)})]
-[2\log \mathcal{L}(\hat{\boldsymbol{\theta}}^{(s)})-2\log \mathcal{L}(\hat{\boldsymbol{\theta}}^{(1)})]\cr
&amp;=L_{0s}-L_{1s}.
\end{align*}\]</span></p>
<p><span class="alert">The log-likelihood ratio statistic for comparing two nested models is the difference of their scaled (or ââresidualââ) deviances.</span></p>
<p>As <span class="math inline">\(p-q=(n-q)-(n-p)\)</span>, the degrees of freedom for the test is the difference in degrees of freedom of the two models.</p>
</section>
<section id="a-redacted-anova-01-vevox.app-160-892-474" class="slide level2">
<h2>A redacted <code>anova</code> 01 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href=""></a>shuttle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/shuttle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb54-2"><a href=""></a>shuttle<span class="sc">$</span>n <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">6</span>, <span class="fu">nrow</span>(shuttle))</span>
<span id="cb54-3"><a href=""></a>shuttle_glm0 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp,           <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span>
<span id="cb54-4"><a href=""></a>shuttle_glm1 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp <span class="sc">+</span> orbiter, <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span>
<span id="cb54-5"><a href=""></a></span>
<span id="cb54-6"><a href=""></a>an_out <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(<span class="fu">anova</span>(shuttle_glm0, shuttle_glm1))</span>
<span id="cb54-7"><a href=""></a>an_out[<span class="dv">7</span>] <span class="ot">&lt;-</span> <span class="st">"2       [B]     [  A  ]  3   1.0238"</span></span>
<span id="cb54-8"><a href=""></a><span class="fu">cat</span>(an_out, <span class="at">fill =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table 
 
Model 1: (n_damaged/n) ~ temp 
Model 2: (n_damaged/n) ~ temp + orbiter 
  Resid. Df Resid. Dev Df Deviance 
1        21       18.1             
2       [B]     [  A  ]  3   1.0238</code></pre>
</div>
</div>
<p>What is <span class="math inline">\(\text{A}\)</span>, the scaled deviance for model <code>shuttle_glm1</code>?</p>
<ul>
<li>17.08</li>
<li>18.08</li>
<li>19.08</li>
</ul>
</section>
<section id="a-redacted-anova-02-vevox.app-160-892-474" class="slide level2">
<h2>A redacted <code>anova</code> 02 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href=""></a>shuttle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/shuttle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb56-2"><a href=""></a>shuttle<span class="sc">$</span>n <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">6</span>, <span class="fu">nrow</span>(shuttle))</span>
<span id="cb56-3"><a href=""></a>shuttle_glm0 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp,           <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span>
<span id="cb56-4"><a href=""></a>shuttle_glm1 <span class="ot">&lt;-</span> <span class="fu">glm</span>((n_damaged <span class="sc">/</span> n) <span class="sc">~</span> temp <span class="sc">+</span> orbiter, <span class="at">data =</span> shuttle, <span class="at">family =</span> binomial, <span class="at">weights =</span> n)</span>
<span id="cb56-5"><a href=""></a></span>
<span id="cb56-6"><a href=""></a>an_out <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(<span class="fu">anova</span>(shuttle_glm0, shuttle_glm1))</span>
<span id="cb56-7"><a href=""></a>an_out[<span class="dv">7</span>] <span class="ot">&lt;-</span> <span class="st">"2       [B]     [  A  ]  3   1.0238"</span></span>
<span id="cb56-8"><a href=""></a><span class="fu">cat</span>(an_out, <span class="at">fill =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table 
 
Model 1: (n_damaged/n) ~ temp 
Model 2: (n_damaged/n) ~ temp + orbiter 
  Resid. Df Resid. Dev Df Deviance 
1        21       18.1             
2       [B]     [  A  ]  3   1.0238</code></pre>
</div>
</div>
<p>What is <span class="math inline">\(\text{B}\)</span>, the DFs for the scaled deviance for <code>shuttle_glm1</code>?</p>
<ul>
<li>17</li>
<li>18</li>
<li>19</li>
</ul>
</section>
<section id="a-note-of-caution" class="slide level2">
<h2>A note of caution</h2>
<p>Recall that we use <span class="math inline">\(L_{0s}\)</span> as a goodness of fit test it by comparing with a <span class="math inline">\(\chi^2_{n-q}\)</span> distribution.</p>
<p>The asymptotic theory used to derive the distribution of the log-likelihood ratio statistic under <span class="math inline">\(H_0\)</span> does not really apply to the goodness of fit test (comparison with the saturated model).</p>
<p>However, for binomial or Poisson data, we can proceed as long as the relevant binomial or Poisson distributions are likely to be reasonably approximated by normal distributions (<strong>i.e.,</strong> <span class="alert">for binomials with large number of trials and probability of success is not too close to 0 or 1, and Poissons with large means</span>).</p>
<p>For <span class="alert">Bernoulli data</span>, we <strong>should not use</strong> the scaled deviance as a goodness of fit statistic in this way.</p>
</section>
<section id="pearsons-x2-statistic" class="slide level2">
<h2>Pearsonâs <span class="math inline">\(X^2\)</span> statistic</h2>
<div class="small-text">
<p>An alternative goodness of fit statistic for a model <span class="math inline">\(H_0\)</span> is Pearsonâs <span class="math inline">\(X^2\)</span> given by <span class="math display">\[
X^2=\sum_{i=1}^n {{\left(y_i-\hat{\mu}_i^{(0)}\right)^2}\over{\widehat{\text{Var}}(Y_i)}}.
\]</span> <span class="math inline">\(X^2\)</span> is small when the squared differences between observed and fitted values (scaled by variance) is small.</p>
<p>So large values of <span class="math inline">\(X^2\)</span> correspond to poor fitting models.</p>
<div class="fragment">
<p>In fact, <span class="math inline">\(X^2\)</span> and <span class="math inline">\(L_{0s}\)</span> are asymptotically equivalent and under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(X^2\)</span> (as with <span class="math inline">\(L_{0s}\)</span>) has an asymptotic <span class="math inline">\(\chi^2_{n-q}\)</span>.</p>
<div class="fragment">
<p>The asymptotics associated with <span class="math inline">\(X^2\)</span> are often more reliable for small samples, so if there is a discrepancy between <span class="math inline">\(X^2\)</span> and <span class="math inline">\(L_{0s}\)</span>, it is usually safer to base a test of goodness of fit on <span class="math inline">\(X^2\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="scaled-deviance-in-terms-of-mean-parameters" class="slide level2">
<h2>Scaled deviance in terms of mean parameters</h2>
<div class="small-text">
<p>Previously, we wrote the scaled deviance in terms of the maximum likelihood estimates of the canonical parameters, as <span class="math display">\[
L_{0s}=2\log \mathcal{L}  \left(\hat{\boldsymbol{\theta}}^{(s)}\right)-2\log \mathcal{L}\left(\hat{\boldsymbol{\theta}}^{(0)}\right),
\]</span></p>
<p>However, it is more usual to express <span class="math inline">\(L_{0s}\)</span> in terms of the maximum likelihood estimates <span class="math inline">\(\hat{\mu}_i,\; i = 1, \cdots, n\)</span> of the mean parameters (<span class="math inline">\(\hat{\theta}_i\)</span> can be less interpretable.).</p>
<div class="fragment">
<ul>
<li>For the saturated model, these are just the observed values <span class="math inline">\(y_i,\;i = 1, \cdots, n\)</span>.</li>
<li>For the model of interest, <span class="math inline">\(H_0\)</span>, we call them the <strong>fitted values</strong>.</li>
</ul>
</div>
</div>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>For a particular generalised linear model, <span class="alert">the scaled deviance function describes how discrepancies between the observed and fitted values are penalised.</span> Essentially, the deviance is a natural measure of âlack of fitâ that aligns with the maximum likelihood approach in each distribution family.</p>
</div>
</div>
</div>
</div>
</section>
<section id="example-poisson" class="slide level2">
<h2>Example (Poisson)</h2>
<div class="small-text">
<p>Suppose <span class="math inline">\(Y_i\sim \text{Poisson}(\lambda_i),\;i = 1, \cdots, n\)</span>.</p>
<p>Recall that <span class="math inline">\(\theta=\log\lambda\)</span>, <span class="math inline">\(b(\theta)=\exp\theta\)</span>, <span class="math inline">\(\mu=b'(\theta)=\exp\theta\)</span>, <span class="math inline">\(a(\phi) = 1\)</span>, and <span class="math inline">\(\text{Var}(Y)=\mu\)</span>.</p>
<p>So <span class="math display">\[\begin{align*}
L_{0s}&amp;=2\sum_{i=1}^n y_i[\log\hat{\mu}^{(s)}_i-\log\hat{\mu}^{(0)}_i]
-[\hat{\mu}^{(s)}_i-\hat{\mu}^{(0)}_i]\cr
&amp;=2\sum_{i=1}^n y_i\log \left({{y_i}\over{\hat{\mu}^{(0)}_i}}\right)
-y_i+\hat{\mu}^{(0)}_i
\end{align*}\]</span> and <span class="math display">\[
X^2=\sum_{i=1}^n {{(y_i-\hat{\mu}_i^{(0)})^2}\over{\hat{\mu}_i^{(0)}}}.
\]</span></p>
</div>
</section>
<section id="example-binomial" class="slide level2">
<h2>Example (Binomial)</h2>
<div class="small-text">
<p>Suppose <span class="math inline">\(Y_i^{\star} \sim \text{Binomial}(n_i,p_i)\)</span>. Let <span class="math inline">\(Y_i = Y_i^{\star}/n,\;i = 1, \cdots, n\)</span> (i.e., we are modelling the <span class="alert"><strong>proportion of successes</strong></span>).</p>
<p><span class="math inline">\(\theta=\log{p\over{1-p}}\)</span>, <span class="math inline">\(b(\theta)=\log(1+\exp\theta)\)</span>, <span class="math inline">\(\mu=b'(\theta)={{\exp\theta}\over{1+\exp\theta}}\)</span> and <span class="math inline">\(\text{Var}(Y)=\frac{\mu\,(1-\mu)}{n}\)</span>.</p>
<p>So <span class="math display">\[\begin{align*}
L_{0s}&amp;=2\sum_{i=1}^n n_iy_i\left[\log{\hat{\mu}^{(s)}_i\over{1-\hat{\mu}^{(s)}_i}}
-\log{\hat{\mu}^{(0)}_i\over{1-\hat{\mu}^{(0)}_i}}\right] + 2\sum_{i=1}^n n_i \left[\log(1-\hat{\mu}^{(s)}_i)-\log(1-\hat{\mu}^{(0)}_i) \right]\cr
&amp;=2\sum_{i=1}^n \left[ n_iy_i\log \left({{y_i}\over{\hat{\mu}^{(0)}_i}}\right)
+n_i(1-y_i) \log \left({{1-y_i}\over{1-\hat{\mu}^{(0)}_i}}\right) \right]
\end{align*}\]</span> and <span class="math display">\[
X^2=\sum_{i=1}^n {{n_i(y_i-\hat{\mu}_i^{(0)})^2}\over{\hat{\mu}_i^{(0)}
(1-\hat{\mu}^{(0)}_i)}}.
\]</span></p>
</div>
</section>
<section id="summary-6" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have looked again at the scaled (or ââresidualââ) deviance, and found how it can be used to calculate the log-likelihood ratio test statistic for comparing nested GLMs.</li>
<li>We have also introduced the Pearsonâs <span class="math inline">\(X^2\)</span> statistic for checking goodness of fit.</li>
<li>Next time, we will consider how to do inference in a GLM with unknown <span class="math inline">\(a(\phi_i)\)</span>.</li>
</ul>
</section></section>
<section>
<section id="chapter-5-generalised-linear-models-lecture-5.8-models-with-unknown-scale" class="title-slide slide level1 center">
<h1><span style="font-size: 42px; color: #131516; display: block; margin-bottom: -50px">Chapter 5: Generalised Linear Models</span> <br> Lecture 5.8: Models with unknown scale</h1>

</section>
<section id="recap-6" class="slide level2">
<h2>Recap</h2>
<p>We have seen how to do inference in a GLM:</p>
<ul>
<li>How to estimate the parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>.</li>
<li>How to find confidence intervals for components of <span class="math inline">\(\boldsymbol{\beta}\)</span>.</li>
<li>How to compare nested models using log-likelihood ratio tests.</li>
</ul>
<p>In all cases, we have so far assumed that <span class="math inline">\(a(\phi)\)</span> is known. <span class="alert"><strong>What if <span class="math inline">\(a(\phi)\)</span> is unknown?</strong></span></p>
</section>
<section id="models-with-unknown-aphi" class="slide level2">
<h2>Models with unknown <span class="math inline">\(a(\phi)\)</span></h2>
<p>So far we have assumed that <span class="math inline">\(a(\phi)\)</span> is known.</p>
<p>This is the case for both the Poisson distribution <span class="math inline">\((a(\phi) = 1)\)</span> and the Binomial distribution when modelling the proportion of successes <span class="math inline">\((a(\phi)= 1/n)\)</span>.</p>
<div class="fragment">
<p>Neither the <span class="alert">scaled deviance</span> nor <span class="alert">Pearsonâs <span class="math inline">\(X^2\)</span> statistic</span> can be evaluated unless <span class="math inline">\(a(\phi)\)</span> is known.</p>
<p>Therefore, when <span class="math inline">\(a(\phi)\)</span> is not known, we cannot use the scaled deviance as a measure of goodness of fit (or to compare models using log-likelihood ratio tests).</p>
</div>
<div class="fragment">
<p>We can develop an alternative test for comparing nested models.</p>
</div>
</section>
<section id="the-deviance-of-the-model" class="slide level2">
<h2>The deviance of the model</h2>
<p>Here we assume that <span class="math inline">\(a(\phi_i)=\sigma^2/m_i,\;i = 1, \cdots, n\)</span> where <span class="math inline">\(\sigma^2\)</span> is a common unknown <span class="alert"><strong>scale parameter</strong></span> and <span class="math inline">\(m_1,\cdots ,m_n\)</span> are known weights.</p>
<div class="fragment">
<p>A linear model takes this form, as <span class="math inline">\(a(\phi_i)=\sigma^2,\;i = 1, \cdots, n\)</span>, so <span class="math inline">\(m_i=1,\;i = 1, \cdots, n\)</span>.</p>
</div>
<div class="fragment">
<p>Under this assumption <span class="math display">\[
L_{0s}={2\over\sigma^2}\sum_{i=1}^nm_iy_i\left[\hat{\theta}^{(s)}_i-\hat{\theta}^{(0)}_i\right]
-m_i\left[b(\hat{\theta}^{(s)}_i)-b(\hat{\theta}^{(0)}_i)\right]
={1\over\sigma^2}D_{0s},
\]</span> where <span class="math inline">\(D_{0s}\)</span> is defined to be twice the sum above, which can be calculated using the observed data. We call <span class="math inline">\(D_{0s}\)</span> the <span class="alert"><strong>unscaled deviance</strong></span> of the model.</p>
</div>
</section>
<section id="comparing-nested-models-an-f-test" class="slide level2">
<h2>Comparing nested models: an <span class="math inline">\(F\)</span> test</h2>
<div class="small-text">
<p>In order to test nested models <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span>, we calculate the test statistic <span class="math display">\[
F={{\frac{L_{01}}{(p-q)}}\over{\frac{L_{1s}}{(n-p)}}}={{\frac{(L_{0s}-L_{1s})}{(p-q)}}\over{\frac{L_{1s}}{(n-p)}}} \;={{\frac{{1\over\sigma^2}\left(D_{0s}-D_{1s}\right)}{(p-q)}}
\over{\frac{{1\over\sigma^2}D_{1s}}{(n-p)}}}
={\frac{{(D_{0s}-D_{1s})}}{(p-q)}\over{\frac{D_{1s}}{(n-p)}}}.
\]</span> This statistic does not depend on the unknown scale parameter <span class="math inline">\(\sigma^2\)</span> (only on the observed data).</p>
<div class="fragment">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Reminder</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\(X \sim \chi^2_p\)</span> and <span class="math inline">\(Y \sim \chi^2_q\)</span> be independent chi-square distributed random variables with degrees of freedom <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>, respectively. Then, <span class="math inline">\(Z = \frac{X/p}{Y/q}\)</span> follows an F-distribution with parameters <span class="math inline">\((p, q)\)</span>, i.e., <span class="math inline">\(Z \sim F_{p, q}\)</span>. Asymptotically, if <span class="math inline">\(X_n\)</span> and <span class="math inline">\(Y_n\)</span> are (asymptotically) independent and satisfy <span class="math inline">\(X_n \overset{d}{\to} \chi^2_p\)</span> and <span class="math inline">\(Y_n \overset{d}{\to} \chi^2_q\)</span>, then it follows that <span class="math inline">\(\frac{X_n/p}{Y_n/q} \overset{d}{\to} F_{p, q}\)</span>.</p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>Asymptotically, under <span class="math inline">\(H_0\)</span>, we have <span class="math inline">\(L_{01} \sim \chi^2_{p-q}\)</span> and <span class="math inline">\(L_{1s} \sim \chi^2_{n-p}\)</span>.</p>
</div>
<div class="fragment">
<p>Furthermore, <span class="math inline">\(L_{01}\)</span> and <span class="math inline">\(L_{1s}\)</span> are independent (<span class="alert"><strong>not proved here</strong></span>) so <span class="math inline">\(F\)</span> has an asymptotic <span class="math inline">\(F_{(p-q), (n-p)}\)</span> distribution. Hence, we reject <span class="math inline">\(H_0\)</span> in favour of <span class="math inline">\(H_1\)</span> if <span class="math inline">\(F\)</span> is too large (for example, greater than the <span class="math inline">\(95\%\)</span> point of the relevant <span class="math inline">\(F\)</span> distribution).</p>
</div>
</div>
</section>
<section id="mle-with-unknown-aphi" class="slide level2">
<h2>MLE with unknown <span class="math inline">\(a(\phi)\)</span></h2>
<div class="small-text">
<p>The MLE of <span class="math inline">\(\beta\)</span> solves <span class="math inline">\(\mathbf{u}(\hat{\boldsymbol{\beta}})={\mathbf 0}\)</span>, where <span class="math display">\[
u_k(\boldsymbol{\beta})= \sum_{i=1}^n{{y_i-b'(\theta_i)}\over{a(\phi_i)}} \cdot {{x_{ik}}\over{b''(\theta_i)g'(\mu_i)}}
=\sum_{i=1}^n{{y_i-\mu_i}\over{\text{Var}(Y_i)}} \cdot {{x_{ik}}\over{g'(\mu_i)}}.
\]</span></p>
<p>Recall we are assuming <span class="math inline">\(a(\phi_i) = \sigma^2/ m_i\)</span>, so <span class="math inline">\(\text{Var}(Y_i) = V(\mu_i) \sigma^2 / m_i\)</span>. So <span class="math display">\[
u_k(\hat{\boldsymbol{\beta}}) =
\sum_{i=1}^n \frac{m_i(y_i-\hat \mu_i)}{V(\hat \mu_i) \sigma^2} \cdot
{{x_{ik}}\over{g'(\hat \mu_i)}} = 0,
\]</span> and multiplying through by <span class="math inline">\(\sigma^2\)</span>, we obtain <span class="math display">\[
u_k(\hat{\boldsymbol{\beta}}) =
\sum_{i=1}^n \frac{m_i(y_i-\hat \mu_i)}{V(\hat \mu_i)} \cdot {{x_{ik}}\over{g'(\hat \mu_i)}} = 0, \quad k = 1, \cdots, p,
\]</span> which we can solve numerically (e.g., via Iteratively Reweighted Least Squares) without ever specifying or estimating <span class="math inline">\(\sigma^2\)</span>.</p>
</div>
</section>
<section id="standard-errors-and-confidence-intervals" class="slide level2">
<h2>Standard errors and confidence intervals</h2>
<p>To find standard errors for <span class="math inline">\(\hat{\beta}_j\)</span>, we do need knowledge of <span class="math inline">\(\sigma^2\)</span>, as <span class="math inline">\(\text{Var}(\hat{\beta}_j)\)</span> depend on <span class="math inline">\(\sigma^2\)</span>.</p>
<div class="fragment">
<p>In fact, asymptotically <span class="math inline">\(\text{Var}(\hat{\boldsymbol{\beta}})\)</span> is the inverse of the Fisher information matrix <span class="math inline">\({\mathcal I}(\boldsymbol{\beta})=\mathbf{X}^{\top}\mathbf{W}\mathbf{X}\)</span>, and this depends on <span class="math inline">\(w_i={1\over{\text{Var}(Y_i)g'(\mu_i)^2}},\)</span> where <span class="math inline">\(\text{Var}(Y_i)=a(\phi_i)b''(\theta_i)=\sigma^2 b''(\theta_i)/m_i\)</span> here.</p>
</div>
<div class="fragment">
<p>To calculate standard errors and confidence intervals, we need to supply an estimate <span class="math inline">\(\hat \sigma^2\)</span> of <span class="math inline">\(\sigma^2\)</span>.</p>
</div>
</section>
<section id="estimating-sigma2-based-on-the-deviance" class="slide level2">
<h2>Estimating <span class="math inline">\(\sigma^2\)</span> based on the deviance</h2>
<p>Often, we do not use the MLE of <span class="math inline">\(\sigma^2\)</span>.</p>
<div class="fragment">
<p>Instead, we notice that <span class="math inline">\(L_{0s}=D_{0s}/\sigma^2\)</span>, and we know that asymptotically, if model <span class="math inline">\(H_0\)</span> is an adequate fit, <span class="math inline">\(L_{0s} \sim \chi^2_{n-q}\)</span>. Hence, <span class="math display">\[
\mathbb{E}\left({1\over{\sigma^2}}D_{0s}\right)=\mathbb{E}(L_{0s})=n-q\quad\overset{\times \frac{\sigma^2}{n-q}}{\implies}\quad
\mathbb{E}\left({1\over{n-q}}D_{0s}\right)=\sigma^2.
\]</span></p>
</div>
<div class="fragment">
<p>Therefore, <span class="alert"><strong>the unscaled deviance of a model divided by its degrees of freedom is an asymptotically unbiased estimator of the scale parameter <span class="math inline">\(\sigma^2\)</span></strong></span>. Thus, <span class="math display">\[\hat\sigma^2=D_{0s}/(n-q).\]</span></p>
</div>
</section>
<section id="estimating-sigma2-based-on-pearsons-x2-statistic" class="slide level2">
<h2>Estimating <span class="math inline">\(\sigma^2\)</span> based on Pearsonâs <span class="math inline">\(X^2\)</span> statistic</h2>
<div class="small-text">
<p>An alternative estimator of <span class="math inline">\(\sigma^2\)</span> is based on the Pearson <span class="math inline">\(X^2\)</span> statistic. It follows that <span class="math display">\[
X^2={1\over\sigma^2}
\sum_{i=1}^n {{m_i\left(y_i-\hat{\mu}_i^{(0)}\right)^2}\over{{V}(\hat{\mu}_i)}}.
\]</span> as <span class="math inline">\(\text{Var}(Y)=a(\phi)V(\mu)=\sigma^2/m\cdot V(\mu)\)</span>. Again, if <span class="math inline">\(H_0\)</span> is an adequate fit, <span class="math inline">\(X^2 \sim \chi^2_{n-q}\)</span>, so <span class="math display">\[
\mathbb{E}\left({1\over\sigma^2}
\sum_{i=1}^n {{m_i\left(y_i-\hat{\mu}_i^{(0)}\right)^2}\over{{V}(\hat{\mu}_i)}}\right) = \mathbb{E}(X^2) = n - q,
\]</span></p>
<div class="fragment">
<p>which implies that <span class="math display">\[
\hat \sigma^2={1\over{n-q}}
\sum_{i=1}^n {{m_i\left(y_i-\hat{\mu}_i^{(0)}\right)^2}\over{{V}(\hat{\mu}_i)}}
\]</span> is an <span class="alert"><strong>alternative unbiased estimator for the scale parameter <span class="math inline">\(\sigma^2\)</span></strong></span>.</p>
</div>
</div>
</section>
<section id="example-normal" class="slide level2">
<h2>Example (Normal)</h2>
<p>Suppose <span class="math inline">\(Y_i\sim \text{Normal}(\mu_i,\sigma^2),\;i = 1, \cdots, n\)</span>. Recall that <span class="math inline">\(\theta=\mu\)</span>, <span class="math inline">\(b(\theta)=\theta^2/2\)</span>, <span class="math inline">\(\mu=b'(\theta)=\theta\)</span> and <span class="math inline">\(\text{Var}(Y)=a(\phi)V(\mu)={\sigma^2}\cdot 1\)</span>, so <span class="math inline">\(m_i=1,\;i = 1, \ldots, n\)</span>.</p>
<p>Therefore, the unscaled deviance is given by <span class="math display">\[
D_{0s}=2\sum_{i=1}^n y_i\left[\hat{\mu}^{(s)}_i-\hat{\mu}^{(0)}_i\right]
-\left[\frac{1}{2}{{\hat{\mu}}^{(s)^2}_i}-\frac{1}{2}{{\hat{\mu}}^{(0)^2}_i}\right]
=\sum_{i=1}^n \left[y_i-\hat{\mu}^{(0)}_i\right]^2,
\]</span> which is just the residual sum of squares for model <span class="math inline">\(H_0\)</span>.</p>
<div class="fragment">
<p>Therefore, <span class="alert">we estimate <span class="math inline">\(\sigma^2\)</span> for a normal GLM by its residual sum of squares for the model divided by its degrees of freedom</span>.</p>
</div>
<div class="fragment">
<p>The estimate for <span class="math inline">\(\sigma^2\)</span> based on <span class="math inline">\(X^2\)</span> is identical.</p>
</div>
</section>
<section id="residuals" class="slide level2">
<h2>Residuals</h2>
<p>Recall that for linear models, we define the residuals to be the differences between the observed and fitted values <span class="math display">\[
y_i-\hat{\mu}^{(0)}_i,\;i = 1, \cdots, n.
\]</span></p>
<div class="fragment">
<p>Both the scaled deviance <span class="math inline">\(L_{0s}\)</span> and Pearson <span class="math inline">\(X^2\)</span> statistic for a normal GLM (i.e., linear model) are the sum of the squared residuals divided by <span class="math inline">\(\sigma^2\)</span> (<strong>from previous slide</strong>).</p>
</div>
<div class="fragment">
<p>We can generalise this to define residuals for other generalised linear models in a natural way.</p>
</div>
</section>
<section id="pearson-residuals-and-deviance-residuals" class="slide level2">
<h2>Pearson residuals and deviance residuals</h2>
<div class="small-text">
<p>For any GLM we define the <span class="alert"><strong>Pearson residuals</strong></span> to be <span class="math display">\[
r^P_i={{y_i-\hat{\mu}_i^{(0)}}\over{\widehat{\text{Var}}(Y_i)^{1\over 2}}}\qquad i = 1, \cdots, n.
\]</span> Then, <span class="math inline">\(X^2\)</span> is the sum of the squared Pearson residuals; that is, <span class="math inline">\(X^2 = \sum_{i = 1}^{n}\left(r^P_i\right)^2.\)</span></p>
<div class="fragment">
<p>For any GLM we define the <span class="alert"><strong>deviance residuals</strong></span> to be <span class="math display">\[
r^D_i=\text{sign}\left(y_i-\hat{\mu}_i^{(0)}\right) \cdot
\left[ 2 \cdot {{y_i\left[\hat{\theta}^{(s)}_i-\hat{\theta}^{(0)}_i\right]
-\left[b\left(\hat{\theta}^{(s)}_i\right)-b\left(\hat{\theta}^{(0)}_i\right)\right]}
\over{a(\phi_i)}}\right]^{1\over 2},
\]</span> <span class="math inline">\(i=1, \cdots, n\)</span>, where <span class="math inline">\(\text{sign}(x)=1\)</span> if <span class="math inline">\(x&gt;0\)</span> and <span class="math inline">\(-1\)</span> if <span class="math inline">\(x&lt;0\)</span>. Then the scaled deviance, <span class="math inline">\(L_{0s}\)</span>, is the sum of the squared deviance residuals. That is, <span class="math inline">\(L_{0s} = \sum_{i = 1}^{n}\left(r^D_i\right)^2.\)</span></p>
</div>
</div>
</section>
<section id="residuals-in-r" class="slide level2">
<h2>Residuals in <code>R</code></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href=""></a>beetle <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/beetle.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb58-2"><a href=""></a>beetle<span class="sc">$</span>exposed     <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">+</span> beetle<span class="sc">$</span>alive</span>
<span id="cb58-3"><a href=""></a>beetle<span class="sc">$</span>prop_killed <span class="ot">&lt;-</span> beetle<span class="sc">$</span>dead <span class="sc">/</span> beetle<span class="sc">$</span>exposed</span>
<span id="cb58-4"><a href=""></a></span>
<span id="cb58-5"><a href=""></a>beetle_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(prop_killed <span class="sc">~</span> dose, <span class="at">data =</span> beetle, <span class="at">family =</span> binomial, <span class="at">weights =</span> exposed)</span>
<span id="cb58-6"><a href=""></a></span>
<span id="cb58-7"><a href=""></a>(resid_pearson  <span class="ot">&lt;-</span> <span class="fu">residuals</span>(beetle_logit, <span class="at">type =</span>  <span class="st">"pearson"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      1       2       3       4       5       6       7       8 
 1.4093  1.1011 -1.1763 -1.6124  0.5944 -0.1281  1.0914  1.1331 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href=""></a>(resid_deviance <span class="ot">&lt;-</span> <span class="fu">residuals</span>(beetle_logit, <span class="at">type =</span> <span class="st">"deviance"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      1       2       3       4       5       6       7       8 
 1.2837  1.0597 -1.1961 -1.5941  0.6061 -0.1272  1.2511  1.5940 </code></pre>
</div>
</div>
</section>
<section id="pearsons-x2-in-r-01-vevox.app-160-892-474" class="slide level2">
<h2>Pearsonâs <span class="math inline">\(X^2\)</span> in <code>R</code> 01 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<p>Which of the following commands would find the Pearsonâs <span class="math inline">\(X^2\)</span> statistic in <code>R</code>?</p>
<ul>
<li><code>sum(resid_pearson)</code></li>
<li><code>sum(abs(resid_pearson))</code></li>
<li><code>sum(resid_pearson^2)</code></li>
<li><code>sum(resid_deviance)</code></li>
<li><code>sum(abs(resid_deviance))</code></li>
<li><code>sum(resid_deviance^2)</code></li>
</ul>
<div class="fragment">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href=""></a><span class="fu">sum</span>(resid_pearson<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10.03</code></pre>
</div>
</div>
</div>
</section>
<section id="pearsons-x2-in-r-02-vevox.app-160-892-474" class="slide level2">
<h2>Pearsonâs <span class="math inline">\(X^2\)</span> in <code>R</code> 02 (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<p>For a goodness of fit test, which distribution should we compare the Pearsonâs <span class="math inline">\(X^2\)</span> statistic (<span class="math inline">\(10.03\)</span>) to here?</p>
<ul>
<li><span class="math inline">\(\chi^2_1\)</span></li>
<li><span class="math inline">\(\chi^2_2\)</span></li>
<li><span class="math inline">\(\chi^2_3\)</span></li>
<li><span class="math inline">\(\chi^2_4\)</span></li>
<li><span class="math inline">\(\chi^2_5\)</span></li>
<li><span class="math inline">\(\chi^2_6\)</span></li>
<li><span class="math inline">\(\chi^2_7\)</span></li>
<li><span class="math inline">\(\chi^2_8\)</span></li>
</ul>
</section>
<section id="pearsons-x2-in-r" class="slide level2">
<h2>Pearsonâs <span class="math inline">\(X^2\)</span> in <code>R</code></h2>
<p>We have <span class="math inline">\(X^2 = 10.0\)</span>, and we should be worried about the fit of the model if <span class="math inline">\(X^2\)</span> exceeds the <span class="math inline">\(95\%\)</span> point of the <span class="math inline">\(\chi^2_6\)</span> distribution</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href=""></a><span class="fu">qchisq</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.59</code></pre>
</div>
</div>
<p>So we have no particular reason to be worried about model fit on the basis of the Pearsonâs <span class="math inline">\(X^2\)</span>.</p>
</section>
<section id="scaled-deviance-in-r-vevox.app-160-892-474" class="slide level2">
<h2>Scaled deviance in <code>R</code> (<a href="https://vevox.app/m#/160892474">vevox.app</a>, 160-892-474)</h2>
<p>Which of the following commands would find the scaled deviance in <code>R</code>?</p>
<ul>
<li><code>sum(resid_pearson)</code></li>
<li><code>sum(abs(resid_pearson))</code></li>
<li><code>sum(resid_pearson^2)</code></li>
<li><code>sum(resid_deviance)</code></li>
<li><code>sum(abs(resid_deviance))</code></li>
<li><code>sum(resid_deviance^2)</code></li>
</ul>
<div class="fragment">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href=""></a><span class="fu">sum</span>(resid_deviance<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 11.23</code></pre>
</div>
</div>
</div>
</section>
<section id="residuals-plots" class="slide level2">
<h2>Residuals plots</h2>
<p>A plot of deviance or Pearson residuals against the linear predictor should produce something that looks like a random scatter.</p>
<div class="fragment">
<p>If not, then this may be due to incorrect link function, wrong scale for an explanatory variable, or perhaps a missing polynomial term in an explanatory variable.</p>
</div>
<div class="fragment">
<p>However, this should be used with some caution; for instance, in the case of a Binomial model with small <span class="math inline">\(n_i\)</span> (and particularly for Bernoulli models, with <span class="math inline">\(n_i = 1\)</span>), patterns may appear in the residual plots even if the assumptions of the model are met.</p>
</div>
</section>
<section id="plotting-the-deviance-residuals-in-r" class="slide level2">
<h2>Plotting the deviance residuals in <code>R</code></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href=""></a><span class="fu">plot</span>(<span class="fu">predict</span>(beetle_logit), resid_deviance)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-39-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"></section>
<section id="plotting-the-pearson-residuals-in-r" class="slide level2">
<h2>Plotting the pearson residuals in <code>R</code></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href=""></a><span class="fu">plot</span>(<span class="fu">predict</span>(beetle_logit), resid_pearson)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="chap_5_files/figure-revealjs/unnamed-chunk-40-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"></section>
<section id="summary-7" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We have seen two definitions of residuals for GLMs, and how they relate to the scaled deviance and the Pearsonâs <span class="math inline">\(X^2\)</span> statistic.</li>
<li>We have seen how to use residual plots to check for potential problems in a model, and decide on possible other models.</li>
</ul>
<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="chap_5_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="chap_5_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="chap_5_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="chap_5_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>